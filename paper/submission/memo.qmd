---
format:
  pdf:
    number-sections: false

bibliography: memo.bib
tables: true # enable longtable and booktabs
fontsize: 10pt
indent: true
geometry: margin=1in
linestretch: 1 # double spacing using linestretch 1.5
colorlinks: true

execute:
  echo: false
  message: false
  warning: false
  dpi: 300
    
title:  Macrointerest Across Countries
subtitle: Memo to Editor and Reviewers
---

```{=tex}
\setcounter{figure}{0}
\renewcommand*{\thefigure}{M\arabic{figure}}
```

```{r setup, include=FALSE}
options(cache = TRUE)
```

\vspace{-.75in}

Thank you for the opportunity to revise and resubmit this manuscript. We detail our responses to each of the reviewers' helpful comments below.

### Introduction {.unnumbered}
**Framing**.
We appreciate the reviewers' careful reading and their suggestions for better framing the piece.
Following Reviewer 1's suggestion, we reorganized the introduction into three paragraphs.
The first addresses the relevance of macrointerest.
Reviewer 2 asked us to provide more theoretical discussion on macrointerest, and minding the editor's instruction to limit this to "a bit more," we did so here. 
The second paragraph reviews the challenges faced by previous research.
R1 specifically suggested that we contrast our work with that of @Peterson2022, and we added that to this second paragraph.
(Also at R1's suggestion, we included an appendix comparing our estimates of macrointerest for the United States with those presented in that article; see Appendix E.)
The third paragraph previews our specific contribution and findings.
We agree that the original introduction was too brisk, and we see this as a substantial improvement.

One point that both reviewers flagged was the "good times versus bad" framing of the hypotheses regarding the circumstances that prompt higher levels of macrointerest, pointing out that this wording does not correspond very well to the paper's findings.
Here in the introduction and throughout, we adopted the more accurate "good economic conditions" phrasing to better reflect the higher mean levels and positive change in GDP per capita plus lower mean levels of income inequality that we found to be associated with higher macrointerest in our analysis.


**Replication Materials**.
R2 longed to see our replication materials during the review process.
We, as reviewers, have often made similar wishes.
We are told by the _BJPS_ editor that making those materials available to reviewers is not presently possible.
In the final version, we will of course provide a link to the full replication materials on the Dataverse as well as the link to the GitHub repository with the paper's complete revision history.


### Cross-National Macrointerest: The Source Data {.unnumbered}
**`DCPOtools`**.
On the recommendation of R1, we expanded and moved our discussion of the automation of the data cleaning process to Appendix A.


### Estimating Cross-National Macrointerest {.unnumbered}
**Method Comparison**. 
R1 suggested that we bring our discussion of the merits of the DCPO approach relative to alternatives from a footnote to the text.
We have adopted this suggestion at pages 3 and 4.


**Northern Ireland**.
R2 asked why we have estimates for Northern Ireland.
The answer is that several surveys---for our purposes here, the EVS, one wave of the European Election Survey, and one wave of ISSP data---include respondents from Northern Ireland but no weights to incorporate them along with British respondents to generate information about the entire United Kingdom.
From the perspective of UK estimates, the inclusion or exclusion of Northern Ireland of course generally matters very little.
But given that we have these data, we had chosen to use it to make estimates just as we do for other subnational territories such as Puerto Rico and Hong Kong---even though, unlike those other territories, if we were truly interested in Northern Ireland, we could also break it out of the UK in other surveys like the Eurobarometer (something we did not do).
Given the sparsity of the source data from Northern Ireland, its inclusion or exclusion does not appreciably affect other macrointerest estimates either.
Nevertheless, in light of R2's apparent skepticism, we now exclude Northern Ireland from the source data.
For transparency, we include a footnote to this effect in the appendix at page A1.

### Validating Cross-National Macrointerest {.unnumbered}
**Correlation Magnitudes**.
R2 raised questions about "the validation exercise," pointing to a "lack of benchmarks" for the "evaluations of the size of the correlation coefficients."
Any benchmark regarding correlation magnitudes is bound to be somewhat arbitrary, but comparisons to the correlations found in prior similar research are at least the best place to start.
The correlations for the similar internal convergent validation tests in @Caughey2019 [, 686, Figure 6, columns 1 and 3], which we cited in this regard (now at page 5), range in absolute value from .73 to .92.
The range of correlations we report on in Figure 2 on page 6, from .72 to .88, seem to us to be similarly satisfying.
The range of the three correlations we present as evidence of construct validation, that is, of effects expected by theory---.47, .51, and .62---dips somewhat lower than that of the two correlations presented as evidence of construct validation in that paper, .60 and .80 [see @Caughey2019, 688], but we note here that characterizing these relationships as "as moderate to strong" (as we do at page 6) is in line with textbook prescriptions: @Cohen1988 [, 78-79], for example, considers $r = .3$ to be evidence of a "medium effect size" and $r = .5$ to evince a "large effect size."


**Large vs Small Projects**.
With regard to internal convergent validation, R2 offered the speculation that items with more observations would yield higher correlations with the macrointerest estimates and that for "small projects with few surveys" the correlation would be smaller in a way that would call into question the utility of the method.
To investigate this possibility, we first calculated the mean response for each item in each country-year observed.
(This is not quite the same aggregation procedure that we use in the plots in the text.
There, we dichotomize the items and take the percentage of respondents giving higher responses, but while that route---despite shortcomings seen under the next subheading---facilitates plotting by yielding results on the unit interval, this one is better suited to scaling across dozens of items.)

```{r itcor, fig.align='center', fig.cap="Relationship Between Items' Correlations with Macrointerest and Their Number of Observations", fig.height=2.5}
library(tidyverse)
library(DCPOtools)

dcpo_input_raw <- read_csv(here::here("data", "dcpo_input_raw.csv"),
                           col_types = "cdcddcd")

load(here::here("data",
                "theta_summary.rda"))

process_dcpo_input_raw <- function(dcpo_input_raw_df) {
  dcpo_input_raw_df %>% 
    mutate(item = if_else(item == "int5_polit" &
                            year < 1990,
                          "int3_polit",
                          item),
           r = if_else(item == "int5_polit" &
                         year < 1990,
                       r - 2,
                       r)) %>% 
    filter(year >= 1982 & n > 0 & !country=="Northern Ireland") %>% 
    with_min_yrs(3) %>% 
    with_min_cy(5) %>% 
    with_min_yrs(3) %>%
    group_by(country) %>% 
    mutate(cc_rank = n()) %>% 
    ungroup() %>% 
    arrange(-cc_rank)
}

dcpo_input_raw1 <- dcpo_input_raw %>% 
  process_dcpo_input_raw()

item_theta_cor <- dcpo_input_raw1 %>% 
  group_by(item) %>% 
  mutate(n_item = sum(r==1)) %>% 
  ungroup() %>% 
  group_by(country, year, item) %>% 
  summarize(mean_item = sum(r*n)/sum(n),
            se_item = sqrt(sum((r*n - mean_item*n)^2)/{sum(n) - 1})/sqrt(sum(n)),
            n_item = first(n_item),
            cc_rank = first(cc_rank)) %>% 
  left_join(theta_summary %>% select(country, year, theta = mean),
            by = c("country", "year")) %>% 
  ungroup() %>% 
  group_by(item) %>% 
  summarize(theta_cor = cor(theta, mean_item),
            n_item = first(n_item))

itcor <- with(item_theta_cor, cor(theta_cor, n_item)) %>% 
  sprintf("%.2f", .) %>% 
  paste("R =", .)

item_theta_cor %>% 
  ggplot(aes(x = n_item, y = theta_cor)) +
  geom_point() +
  geom_smooth(method="lm") +  # Add linear regression line 
  ylim(c(0, 1)) +
  labs(x = "Item Number of Country-Year Observations",
    y = "Correlation Between\nItem Country-Year Means\nand Macrointerest Estimates") +
  annotate(geom = "text", 
           x = 265,
           y = 1,
           label = itcor)
```

Then we calculated the correlation for each item across country-years between these mean responses and the macrointerest estimates.
This correlation was .9 or higher for twenty-seven of our fifty-four items; it was below .7 for just three.
Finally, we observed the relationship between, on the one hand, each item's correlations with the macrointerest estimates, and, on the other, the number of observations it provides.
This relationship is weak, as shown in Figure M1, and is in the direction contrary to R2's hypothesis.

In short, Figure 2 does not represent a particularly lucky walk through the garden of forking paths---or worse, one intentionally chosen to flatter the method.
The particularly data-rich items it depicts do correlate well with the macrointerest estimates, but that is also true for nearly all of the items.


**ALLBUS**.
Pointing to our longitudinal internal convergent validation test in the right panel of Figure 2, R2 noted that "the time series of Allbus and Macrointerest don't actually seem to covary very well," specifically around the year 2000, when there is a sharp dip in the macrointerest estimates that is absent in the ALLBUS series displayed.
The reviewer observed that this was "concerning": if anything, the macrointerest estimates should be _more_ smooth than the underlying survey data, not less.
She or he suggested we investigate and explain the divergence.

We thank R2 for raising the issue and took this advice.
We discovered that the apparent divergence was really just an artifact of the way we had dichotomized the ALLBUS data in the original figure.
There, we took the percentage of respondents who said that they were 'strongly' or 'very strongly' interested in politics, that is, those who answered at least a 4 on the item's five-point scale.
In Figure M2, we plot the percentage of ALLBUS respondents who give a response at least as high as each of this scale's four higher values (of course, 100% of respondents give a response at least as high as the lowest value).
It shows that, for this item, the real action from 1998 to 2000 occurred in the percentage of people giving a response at least in the median category of 'middling' (the solid orange series labeled '3+' that varies around .75 in Figure M2), and to a lesser degree, the percentage expressing at least 'very little' interest (the solid yellow '2+' series).
As can be seen in the lighter shades in the plot, the five-point Politbarometer item (the other long-running German survey series) shows this decline in political interest from 1999 to 2000 more consistently across its response categories, with the rebounds in 2001 stronger in the 4+ and 5 responses.

```{r dets, fig.align='center', fig.cap="Time Series on Political Interest in Germany", fig.height=2.5}
load(here::here("data", "dcpo_input.rda"))

dcpo_input_de <- dcpo_input$data %>% 
  filter(country == "Germany" &
           str_detect(item, "5_polit|allbus")) %>% 
  group_by(item) %>% 
  transmute(year,
            item,
            survey = str_extract(item, "polit|allbus") %>% 
              str_replace("polit", "Politbarometer") %>% 
              str_replace("allbus", "ALLBUS"),
            point = str_extract(item, "\\b\\d"),
            point = if_else(point < 5, paste0(point, "+"), point),
            perc = y_r/n_r,
            perc_n = perc/(mean(perc)))
  

ggplot(dcpo_input_de,
       aes(year, perc, 
           group = item, 
           color = point,
           linetype = survey,
           alpha = survey)) +
  geom_point() + 
  geom_line() + 
  xlab("Year") +
  ylab("% Expressing Political Interest\nby Response Category") +
  scale_color_manual(values = rev(hcl.colors(4, "inferno")),
                     name="Response Category") +
  scale_alpha_discrete(range = c(1, .4),
                       name = "Survey") +
  scale_linetype_discrete(name = "Survey")

```

So what to do?
We could show the mean values of the ALLBUS data in Figure 2.
These means show the dip at the millennium; their correlation with the macrointerest estimates is _r_\nobreakspace{}=\nobreakspace{}`r item_theta_cor %>% filter(item == "int5_allbus") %>% pull(theta_cor) %>% round(2)`.
But this would require adding a second y-axis to facilitate comparison---the means are typically about 3 and so do not fit on the unit interval---and, like [Hadley Wickham](https://stackoverflow.com/questions/3099219/ggplot-with-2-y-axes-on-each-side-and-different-scales/3101876#3101876) and others, we prefer to avoid using second axes.
We opted to show instead the 'percentage of respondents expressing middling or more political interest' series (that is, the now-familiar '3+' orange line in Figure M2).
This provides a pretty plot, possibly slightly understates the correlation between the ALLBUS and the macrointerest estimates in a pleasingly conservative fashion, and avoids prompting unnecessary concern.


**Levels of Analysis**.
With regard to the construct validation tests presented in Figure 3, R2 raised the issue of whether we should expect that established individual-level relationships (such as between political interest and news consumption) to translate to the macro level.
Moving between levels of analysis is admittedly and notoriously fraught.
But the difficulty lies in attributing relationships found at the macro level to the individual level---that is the classic ecological fallacy---not the reverse.
In fact, our proposition here that country-year-level measures should reflect relationships shown in individual-level studies closely follows the recommendation that "analyses of system-level data ought first to look carefully at individual-level association" [@Seligson2002, 288].
(We note that the analysis we offer in Figure 5 draws exclusively on macro-level contextual variables---acknowledging but not accepting the possible argument against characterizing unemployment as contextual---and so does not run afoul of this stricture.
On this parenthetical point, we now highlight the contextual nature of the theories we address at page 9.)


### Testing Theories of Macrointerest Cross-Nationally {.unnumbered}
**Interest vs Engagement**.
R2 writes, "The application tests theories of political participation and how they explain macrointerest. To me this looks like an attempt to check whether macrointerest is similar or different from other forms of participation/engagement. I would have liked to see this discussed in the conclusions."
This is a reasonable supposition---interest is an important aspect of engagement---but this is not our intent, which is simply to understand better what drives differences in macrointerest (as noted just above, we have expanded our introduction to these theories to make this point more clearly).
All of the works whose theories we summarize examine how contextual factors influence political interest in particular (albeit sometimes within broader studies of engagement), and as _contextual_ arguments specifically implicate the overall level of interest in the public, that is, macrointerest.
We are reluctant to opine on the extent to which macrointerest is similar or different from other forms of political engagement without actually examining these other activities, and that is really beyond the scope of this piece.
But we wholeheartedly endorse the reviewer's underlying point that these are interesting questions that our macrointerest data open to further investigation, and so in our conclusion we encourage their use to explore macrointerest's relationships with other aspects of political engagement in future research.


**Comparison to the ESS**.
R2 asked why we would analyze macrointerest in only the advanced democracies of the OECD when we could simply use the ESS data "and save ourselves all the harmonization effort?"
We thank the reviewer for bringing up this point because it would likely cross the minds of many readers.
It is two-pronged.
To address its first part, we examine the advanced democracies because that is where the extant theories of macrointerest apply.
To our knowledge, political scientists have as yet had relatively little to say regarding, for example, explanations for the public's interest in politics in authoritarian countries.
We now emphasize that we restrict our sample for theoretical reasons at page 7.

The question of the payoff of the effort to generate our estimates is easily answered, even within this sample of relatively data-rich countries.
Our macrointerest estimates, by drawing on all of the available survey data on political interest, provide _many_ more country-years to work with than the ESS (which is, as R2 implied, the best alternative).
The ESS includes only 18% of the country-year observations that our macrointerest data make available.
We review this key advantage at page 10 and in greater depth in Appendix C.


**Two-Step Approach**.
R1 raised the question whether the analysis "could be achieved in a single step by integrating hierarchical priors into the model."
We confess we were puzzled by this comment, but we guessed the reviewer was referring to combining the measurement and analysis steps into a single model, as in @Claassen2022.
We prefer to avoid such an approach, because it assumes that the indicators of macrointerest are missing at random with regard to the independent variables, and therefore that the relationship between macrointerest and these independent variables is the same in the country-years when and where macrointerest is poorly observed as in the country-years where macrointerest is well observed.
This assumption is difficult to justify.
If the reviewer had a different "single step" analysis in mind, we apologize for not being able to figure it out.


**Uncertainty**. 
R1 suggested that we provide more details about how we incorporated uncertainty in our analysis.
This is an important point, and we have added a discussion of our approach at page 11. 
We use the "Method of Composition" to account for the uncertainty in the ex post analysis based on the estimated latent variable together with others. 
This is a method that has been often employed in latent variable analyses in political science. 
We now cite several of these applications and also direct readers to a more detailed technical note of how the method is incorporated in the DCPO framework.


**Results**.
R2 pointed out some infelicities in wording in our discussion of the results in this section and suggested that speaking in terms of posterior probabilities would help.
We are grateful for this recommendation and have adopted it at pages 11 and 12.


### Appendices {.unnumbered}

### Survey Items Used to Estimate Macrointerest {.unnumbered}
**Included Projects**.
R2 queried if "single-country and single-wave projects should be included."
All of the survey items we employ include at least five country-years of data (a point we now make explicit at page 2 of the text).
This means that single-wave projects include at least five countries, as exemplified in these data by the survey "Values and Political Change in Post-Communist Europe, 1993-1994."
Even such small cross-national surveys contain at least some information regarding the differences across countries; the cost is that country-specific item bias cannot be estimated and so is set to zero, potentially resulting in additional measurement error.
It also means that single-country projects incorporate at least five years (in fact, the minimum in this dataset is seven, in both the Canadian  Election Studies and the Korea Barometer).
This provides considerable information about changes over time within those countries, and country-specific item bias is of course not an issue for data drawn from only a single country.
We discuss this issue in a footnote in the next appendix.


**Full Survey References**.
R2 asked for additional information in Appendix A on the source data,
requesting "references to all survey datasets used in the analysis."  We now provide citations to all of the surveys in Table A2. As the reviewer anticipated, this did indeed "take many pages," but we agree that it is a valuable addition.


**Legibility of Figure A1**.
R2 also pointed out that Figure A1 was hard to read and suggested splitting it. 
We have split that figure into several panels by region to allow it to be displayed across pages and so enlarged for better legibility. 


### The DCPO Model {.unnumbered}
**Source Data Sample Representation**.
R2 pointed out the matter of sample representation.
We have added a paragraph discussing the issue here.
The short of it is that unlike the model employed by @Caughey2019, the DCPO model does not incorporate a poststratification component to correct for this problem, and the result is greater measurement uncertainty in the estimates where data is relatively rich and potential bias in the estimates where data is more sparse.


**Scaling of Estimates**. 
R1 suggested that we consider employing the cumulative distribution function (CDF) of the normal distribution---that is, the probit transformation---as an alternative to the logistic transformation, for scaling responses on the unit interval within the DCPO framework or at least discuss the relative merits of the two in the appendix.
We appreciate the suggestion of the probit transformation.
The preference for the logistic function in the DCPO model is grounded in its inherent flexibility and enhanced tolerance for deviations from standard normal assumptions. 
Pertinently, within the macrointerest context, we see little reason to presume that the the source data are devoid of extreme values or adhere to a symmetric distribution. 
The logistic transformation exhibits greater leniency under such conditions compared to the normal CDF. 
On the other hand, we concur with R1 that the interpretation of the probit transformation is more intuitive.
We have added a discussion of these points to Appendix B, our summary of the DCPO model.
And as the DCPO model is published as open source software on CRAN [@Solt2020a], future researchers have the option of modifying the transformation method if they see fit. 


### Macrointerest Scores Over Time {.unnumbered}

R2 asked that we include "the trajectories for all countries" in an appendix.
We have added those plots here as Appendix D.

## References {-} 

