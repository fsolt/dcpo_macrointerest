---
output: 
  bookdown::pdf_document2:
    fig_caption: yes
    keep_tex: yes
    toc: no
    number_sections: yes
    latex_engine: xelatex
    pandoc_args: --lua-filter=multibib.lua
title: Macrointerest Across Countries
date: "`r format(Sys.time(), '%B %d, %Y')`"

editor_options: 
  markdown: 
    wrap: sentence
  chunk_output_type: console

tables: true # enable longtable and booktabs
citation_package: natbib
citeproc: false
fontsize: 12pt
indent: true
linestretch: 1.5 # double spacing using linestretch 1.5
bibliography:
  text: dcpo-macrointerest.bib
  app: dcpo-macrointerest-app.bib
biblio-style: apsr
citecolor: black
linkcolor: black
endnote: no
header-includes:
      - \usepackage{array}
      - \usepackage{caption}
      - \usepackage{graphicx}
      - \usepackage{siunitx}
      - \usepackage{colortbl}
      - \usepackage{multirow}
      - \usepackage{hhline}
      - \usepackage{calc}
      - \usepackage{tabularx}
      - \usepackage{threeparttable}
      - \usepackage{wrapfig}
      - \usepackage{fullpage}
      - \usepackage{lscape} #\usepackage{lscape} better for printing, page displayed vertically, content in landscape mode, \usepackage{pdflscape} better for screen, page displayed horizontally, content in landscape mode
      - \newcommand{\blandscape}{\begin{landscape}}
      - \newcommand{\elandscape}{\end{landscape}}
      - \usepackage{titlesec}
      - \titleformat*{\section}{\normalsize\bfseries}
      - \titleformat*{\subsection}{\normalsize\itshape}
      - \usepackage{titling} #use \maketitle repeatedly  
      - \renewcommand{\topfraction}{.85} # Adjust LaTeX placement rules per 
      - \renewcommand{\textfraction}{.15}
      - \renewcommand{\floatpagefraction}{.66}
      - \setcounter{topnumber}{3}
      - \setcounter{bottomnumber}{3}
      - \setcounter{totalnumber}{4}
      - \renewcommand{\bottomfraction}{.7} # https://bookdown.org/yihui/rmarkdown-cookbook/figure-placement.html
---

\pagenumbering{gobble}

# Authors {.unnumbered}

Yue Hu, ORCID: <https://orcid.org/0000-0002-2829-3971>, Associate Professor, Department of Political Science, Tsinghua University, [yuehu\@tsinghua.edu.cn](mailto:yuehu@tsinghua.edu.cn){.email}

\vspace{1cm}

\noindent Frederick Solt, ORCID: <https://orcid.org/0000-0002-3154-6132>, Associate Professor, Department of Political Science, University of Iowa, [frederick-solt\@uiowa.edu](mailto:frederick-solt@uiowa.edu){.email}

\pagebreak

```{=tex}
\renewcommand{\baselinestretch}{1}
\selectfont
\maketitle
\renewcommand{\baselinestretch}{1.5}
\selectfont
```

```{=tex}
\begin{abstract}
The extent to which the public takes an interest in politics has long been argued to be foundational to democracy, but the want of appropriate data has prevented cross-national and longitudinal analysis. This letter takes advantage of recent advances in latent-variable modeling of aggregate survey responses and a comprehensive collection of survey data to generate dynamic comparative estimates of macrointerest, that is, aggregate political interest, for over a hundred countries over the past four decades. These macrointerest scores are validated with other aggregate measures of political interest and of other types of political engagement. A cross-national and longitudinal analysis of macrointerest in advanced democracies reveals that along with election campaigns and inclusive institutions, it is good (economic) times, not bad, that spur publics to greater interest in politics. 
\end{abstract}
```
\pagebreak

\pagenumbering{arabic}

```{r setup, include=FALSE}
options(tinytex.verbose = TRUE)

knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  dpi = 600,
  cache = TRUE,
  fig.width = 7,
  fig.height = 4,
  plot = function(x, options) {
    hook_plot_tex(x, options)
  }
)

# If `DCPOtools` is not yet installed:
# remotes::install_github("fsolt/DCPOtools")

if (!require(pacman)) install.packages("pacman")
library(pacman)
# load all the packages you will use below 
p_load(
  DCPOtools,
  cmdstanr,
  tidyverse,
  here,
  rio,
  countrycode,
  patchwork,
  ggthemes,
  ggdist,
  imputeTS,
  rsdmx,
  osfr,
  tabulizer,
  brms,
  tidybayes,
  repmis,
  rvest,
  vroom,
  modelsummary,
  kableExtra
) 
```

```{r define_funs}
# define functions
validation_plot <- function(v_data_raw,
                            lab_x = .38, lab_y = 92,
                            theta_summary, theta_results) {
    
    # defaults per https://stackoverflow.com/a/49167744/2620381
    if ("theta_summary" %in% ls(envir = .GlobalEnv) & missing(theta_summary))
        theta_summary <- get("theta_summary", envir = .GlobalEnv)
    if ("theta_results" %in% ls(envir = .GlobalEnv) & missing(theta_results))
        theta_results <- get("theta_results", envir = .GlobalEnv)

    median_val <- Vectorize(function(x) median(1:x),
                            vectorize.args = "x")
    
    v_vars <- v_data_raw %>% 
      select(item0 = item,
             title = title) %>% 
      distinct() %>% 
      mutate(v_val = str_extract(item0, "\\d+") %>% 
               as.numeric() %>% 
               median_val(.) %>%
               `+`(if_else(str_detect(item0, "disc3"), .1, .6)) %>% 
               round())
    
    validation_summarized <- v_data_raw %>% 
      DCPOtools::format_dcpo(scale_q = v_vars$item0[[1]], # these arguments are required
                             scale_cp = 1) %>% # but they don't matter
      pluck("data") %>% 
      mutate(item0 = str_remove(item, " \\d or higher")) %>% 
      right_join(v_vars, by = "item0") %>%
      arrange(title) %>% 
      mutate(title = factor(title, 
                            levels = v_data_raw %>%
                              pull(title) %>%
                              unique())) %>% 
      filter(str_detect(item, paste(v_val, "or higher"))) %>%
      mutate(iso2c = countrycode::countrycode(country,
                                              origin = "country.name",
                                              destination = "iso2c",
                                              warn = FALSE),
             prop = y_r/n_r,
             se = sqrt((prop*(1-prop))/n),
             prop_90 = prop + qnorm(.9)*se,
             prop_10 = prop - qnorm(.9)*se) %>%
      inner_join(theta_summary %>% select(-kk, -tt), by = c("country", "year"))
    
    validation_cor <- theta_results %>%
      inner_join(validation_summarized %>%
                   select(country, year, title, prop, se),
                 by = c("country", "year")) %>% 
      rowwise() %>% 
      mutate(sim = rnorm(1, mean = prop, sd = se)) %>% 
      ungroup() %>% 
      select(title, theta, sim, draw) %>% 
      nest(data = c(theta, sim)) %>% 
      mutate(r = lapply(data, function(df) cor(df)[2,1]) %>% 
               unlist()) %>%
      select(-data) %>% 
      group_by(title) %>% 
      summarize(r = paste("R =", round(mean(r), 2)))

    if ({validation_summarized %>%
        pull(country) %>%
        unique() %>% 
        length()} > 1) {
      val_plot <- validation_summarized %>%
        ggplot(aes(x = mean,
                   y = prop * 100)) +
        geom_segment(aes(x = q10, xend = q90,
                         y = prop * 100, yend = prop * 100),
                     na.rm = TRUE,
                     alpha = .2) +
        geom_segment(aes(x = mean, xend = mean,
                         y = prop_90 * 100, yend = prop_10 * 100),
                     na.rm = TRUE,
                     alpha = .2) +
        geom_smooth(method = 'lm', formula = 'y ~ x', se = FALSE) +
        facet_wrap(~ title, ncol = 4) +
        geom_label(data = validation_cor, aes(x = lab_x,
                                              y = lab_y,
                                              label = r),
                   size = 2)
    } else {
      val_plot <- validation_summarized %>%
        ggplot(aes(x = year,
                   y = mean)) +
        geom_line() +
        geom_ribbon(aes(ymin = q10,
                        ymax = q90,
                        linetype = NA),
                    alpha = .2) +
        geom_point(aes(y = prop),
                   fill = "black",
                   shape = 21,
                   size = .5,
                   na.rm = TRUE) +
        geom_path(aes(y = prop),
                  linetype = 3,
                  na.rm = TRUE,
                  alpha = .7) +
        geom_segment(aes(x = year, xend = year,
                         y = prop_90, yend = prop_10),
                     na.rm = TRUE,
                     alpha = .2) +
        facet_wrap(~ title, ncol = 4) +
        geom_label(data = validation_cor, aes(x = lab_x,
                                              y = lab_y,
                                              label = r),
                   size = 2)
    }
    
    return(val_plot)
}

covered_share_of_spanned <- function(dcpo_input_raw) {
  n_cy <- dcpo_input_raw %>%
    distinct(country, year) %>% 
    nrow()
  
  spanned_cy <- dcpo_input_raw %>% 
    group_by(country) %>% 
    summarize(years = max(year) - min(year) + 1) %>% 
    summarize(n = sum(years)) %>% 
    pull(n)
  
  {(n_cy/spanned_cy) * 100}
}

get_coef <- function(iv, results_df = coef_data, type = "both", width = .95) {
  result_var <- results_df %>% 
    filter(.width == width) %>% 
    pull(.variable) %>% 
    str_subset(iv)
  
  if (!type=="both") {
    res <- results_df %>% 
      filter(.variable == result_var & .width == width) %>% 
      pull({{type}})
  } else {
    sc <- results_df %>% 
      filter(.variable == result_var & .width == width) %>% 
      pull(std_coef)
    
    ci <- results_df %>% 
      filter(.variable == result_var & .width == width) %>% 
      pull(ci)
    
    res <- paste0(sc, " (95% c.i.: ", ci, ")")
  }
  
  return(res)
}

by2sd <- function(var) {
  dich <- stats::na.omit(unique(var)) %>% 
    sort() %>% identical(c(0, 1))
  if (dich) 
    sd <- 1
  else 
    sd <- 2 * stats::sd(var, na.rm = TRUE)
  
  return(sd)
}

set.seed(324)
```


# Introduction {.unnumbered}

The public's interest in politics has long been argued to be fundamental to democracy, the foundation for the widespread civic engagement needed to hold elected officials accountable to citizen demands [see, e.g., @Almond1963]. 
<!-- Recent research highlights the substantial influence of political interests in shaping how people process political information, develop attitudes, and respond to political inquiries [@MillerEtAl2023].  -->
More than just boosting engagement, political interest critically determines the quality of political decisions and behaviors, influencing factors like time spent, information collection and utilization, and critical assessment of partisan claims [see, e.g., @LaneEtAl2022].
In light of the growing threats to democracy seen in many countries, measuring the levels and trends of aggregate political interest---macrointerest---and understanding their sources is therefore crucially important [see, e.g., @Foa2016, 10-11]. 

A recent contribution, @Peterson2022, measures macrointerest over time in the United States, but similar data allowing for large-scale cross-sectional time-series assessments have as yet been unavailable.
Although many surveys ask respondents across countries how interested they are in politics, differences in question wording and in response categories have limited scholars' ability to pool the data together, and even in the absence of these issues, in most countries the questions have not been asked sufficiently frequently to provide annual time series.

This letter takes advantage of recent advances in latent-variable modeling of cross-national aggregate survey responses and a comprehensive collection of survey data to generate dynamic comparative estimates of aggregate political interest for over a hundred countries over the past four decades.
It shows that these cross-national macrointerest scores perform well in validation tests.
Finally, as a demonstration of their utility, the letter presents a new test of theories on the circumstances that induce the publics of advanced democracies to take more interest in politics.
The results support arguments that, in these countries, election campaigns, inclusive institutions, and good economic times, not bad ones, spur greater political interest.

```{r dcpo_input_raw, eval=FALSE}
surveys_interest <- read_csv(here::here("data-raw",
                                        "surveys_interest.csv"),
                             col_types = "cccccc")

# dcpo_input_raw <- dcpo_setup(vars = surveys_interest,
#                                         datapath = here("data",
#                                                         "dcpo_surveys"),
#                                         file = here("data",
#                                                     "dcpo_input_raw.csv"))
```

```{r tb_summary_stats}
surveys_interest <- read_csv(here::here("data-raw",
                                        "surveys_interest.csv"),
                             col_types = "cccccc")

dcpo_input_raw <- read_csv(here::here("data", "dcpo_input_raw.csv"),
                                  col_types = "cdcddcd")

process_dcpo_input_raw <- function(dcpo_input_raw_df) {
  dcpo_input_raw_df %>% 
    with_min_yrs(3) %>% 
    with_min_cy(5) %>% 
    with_min_yrs(3) %>%
    filter(year >= 1982 & n > 0) %>% 
    group_by(country) %>% 
    mutate(cc_rank = n()) %>% 
    ungroup() %>% 
    arrange(-cc_rank)
}

dcpo_input_raw1 <- dcpo_input_raw %>% 
  process_dcpo_input_raw()

n_surveys <- surveys_interest %>% 
  distinct(survey) %>% 
  nrow()

n_items <- dcpo_input_raw1 %>%
  distinct(item) %>% 
  nrow()

n_countries <- dcpo_input_raw1 %>%
  distinct(country) %>% 
  nrow()

n_cy <- dcpo_input_raw1 %>%
  distinct(country, year) %>% 
  nrow() %>% 
  scales::comma()

n_years <- as.integer(summary(dcpo_input_raw1$year)[6]-summary(dcpo_input_raw1$year)[1])

spanned_cy <- dcpo_input_raw1 %>% 
  group_by(country) %>% 
  summarize(years = max(year) - min(year) + 1) %>% 
  summarize(n = sum(years)) %>% 
  pull(n) %>% 
  scales::comma()

total_cy <- {n_countries * n_years} %>% 
  scales::comma()

year_range <- paste("from",
                    summary(dcpo_input_raw1$year)[1],
                    "to",
                    summary(dcpo_input_raw1$year)[6])

n_cyi <- dcpo_input_raw1 %>% 
  distinct(country, year, item) %>% 
  nrow() %>% 
  scales::comma()

back_to_numeric <- function(string_number) {
  string_number %>% 
    str_replace(",", "") %>% 
    as.numeric()
}

covered_share <- covered_share_of_spanned(dcpo_input_raw1)
```


# Cross-National Macrointerest: The Source Data {.unnumbered}

National and cross-national surveys have asked questions on political interest often over the past four decades, but the resulting data are both sparse, that is, unavailable for many countries and years, and incomparable, generated by many different survey items.
In all, `r n_items` such survey items were asked in no fewer than five country-years in countries surveyed at least twice; these items were drawn from `r n_surveys` different survey datasets (see online Appendix\nobreakspace{}\@ref(surveys)).

Together, the survey items in the source data were asked in `r n_countries` different countries in at least three time points over the `r n_years` years `r year_range`, yielding a total of `r n_cyi` country-year-item observations.
Observations for every year in each country surveyed would number `r total_cy`, and a complete set of country-year-items would encompass `r {n_countries * n_years * n_items} %>% scales::comma()` observations.
Compared to this hypothetical complete set of country-year-items, the available data are very, very sparse.
More optimistically, there are `r n_cy` country-years in which there is at least _some_ information about the public's interest in politics, that is, some `r round(covered_share)`% of the `r spanned_cy` country-years spanned by these data.
Still, the multitude of different survey items makes these data incomparable and difficult to use together.

```{r itemcountry, fig.cap="Countries and Years with the Most Observations in the Source Data \\label{item_country_plots}", fig.height=3.5, fig.pos='h', cache=FALSE}
items_plot <- dcpo_input_raw1 %>%
  distinct(country, year, item) %>%
  count(item) %>%
  arrange(desc(n)) %>% 
  # head(12) %>% 
  ggplot(aes(forcats::fct_reorder(item, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Country-Years\nObserved") +
  ggtitle("Items")

int4_ess_cy <- dcpo_input_raw1 %>% 
  filter(item == "int4_ess") %>%
  distinct(country, year) %>%
  nrow()

int4_ess_surveys <- dcpo_input_raw1 %>%
  filter(item == "int4_ess") %>%
  distinct(survey) %>%
  pull(survey) %>% 
  str_split(", ") %>% 
  unlist() %>% 
  unique() %>% 
  sort()


countries_plot <- dcpo_input_raw1 %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country)) %>% 
  distinct(country, year, item) %>% 
  count(country) %>%
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Year-Items\nObserved") +
  ggtitle("Countries")

cby_plot <- dcpo_input_raw1 %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country),
         country = stringr::str_replace(country, "South", "S.")) %>% 
  distinct(country, year) %>%
  count(country) %>% 
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Years\nObserved") +
  ggtitle("Countries")


ybc_plot <- dcpo_input_raw1 %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>%
  ggplot(aes(year, nn)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        # axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Countries\nObserved") +
  ggtitle("Years")

de_obs <- dcpo_input_raw1 %>% 
  distinct(country, year, item) %>%
  count(country) %>%
  filter(country == "Germany") %>%
  pull(n)

others <- dcpo_input_raw1 %>%
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(desc(n)) %>%
  slice(2:5) %>%
  pull(country) %>% 
  knitr::combine_words() %>% 
  str_replace_all("(United|Netherlands)", "the \\1")

countries_cp <- dcpo_input_raw1 %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country),
         country = stringr::str_replace(country, "South", "S.")) %>% 
  distinct(country, year, item) %>%
  count(country) %>% 
  arrange(desc(n)) %>% 
  head(12) %>% 
  pull(country)

countries_cbyp <- dcpo_input_raw1 %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country),
         country = stringr::str_replace(country, "South", "S.")) %>% 
  distinct(country, year) %>%
  count(country) %>% 
  arrange(desc(n)) %>% 
  head(12) %>% 
  pull(country)

adding <- setdiff(countries_cbyp, countries_cp) %>% 
  knitr::combine_words()

dropping <- setdiff(countries_cp, countries_cbyp) %>% 
  knitr::combine_words()

y_peak_year <- dcpo_input_raw1 %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>% 
  filter(nn == max(nn)) %>% 
  pull(year)

y_peak_nn <- dcpo_input_raw1 %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>% 
  filter(nn == max(nn)) %>% 
  pull(nn)

data_poorest <- dcpo_input_raw1 %>%
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(n) %>%
  filter(n == 3) %>%
  pull(country) %>% 
  knitr::combine_words() %>% 
  paste0("---", ., "---")

wordify_numeral <- function(x) setNames(c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", " seventeen", "eighteen", "nineteen"), 1:19)[x]

n_data_poor <- {data_poorest %>%
    str_split(",") %>% 
    first()} %>% 
  length() 

if(n_data_poor < 20) {
  n_data_poorest <- n_data_poor %>% 
    wordify_numeral()
} else {
  n_data_poorest <- n_data_poor
  data_poorest <- " "
}

(countries_plot + cby_plot) / (ybc_plot)
```

In the top left panel of Figure\nobreakspace{}\@ref(fig:item_country_plots), the twelve countries with the most country-year-item observations is displayed.
Germany, with `r de_obs` observations, is the best represented country in these source data, followed by `r others`.
At the other end of the scale, there are `r n_data_poorest` countries`r data_poorest`that have only the bare minimum three observations needed to be included in the source dataset at all.
In the top right panel are the dozen countries with the most observed years; this group is similar to that on the left, but with `r adding` adding to the list and `r dropping` dropping off.
The bottom panel shows the number of countries observed in each year.
Coverage across countries reached its apex in `r y_peak_year`, when respondents in `r y_peak_nn` countries were asked at least one item about their interest in politics.
The next section describes how this sparse and incomparable survey data was used together with a latent variable model to generate complete time series of macrointerest scores that are comparable across countries.


# Estimating Cross-National Macrointerest {.unnumbered}

Several recent studies have developed latent variable models of aggregate survey responses based on cross-national survey data [see @Claassen2019; @Caughey2019; @McGann2019; @Kolczynska2020].
To estimate the public's interest in politics across countries and over time, this work employs the latest of these methods that is appropriate for data that are both incomparable and sparse, the Dynamic Comparative Public Opinion (DCPO) model elaborated in @Solt2020c.
@Solt2020c demonstrates that the DCPO model provides a better fit to survey data than the models put forward by @Claassen2019 or @Caughey2019.
The @McGann2019 model depends on dense survey data unlike the sparse data on interest in politics described in the preceding section.
@Kolczynska2020 is the very most recent of these five works and builds on each of the others, but the MRP approach developed in that piece is suitable not only when the available survey data are dense but also when ancillary data on population characteristics are available, so it is similarly inappropriate to this application.
The dyad ratio algorithm employed in @Peterson2022, of course, leverages only over time variation within a single country and not variation across countries, making it a poor choice for generating cross-national estimates [see @Caughey2019, 686].^[
A comparison of our estimates for the United States and the estimates presented in @Peterson2022 is found in Appendix\nobreakspace{}\@ref(peterson).]
The DCPO model is a population-level two-parameter ordinal logistic item response theory model with country-specific item-bias terms.
For a comprehensive description of the DCPO model, see Appendix\nobreakspace{}\@ref(dcpo) and @Solt2020c [, 3-8]; the focus here is on how it deals with the two principal issues raised by the source data, incomparability and sparsity.

The DCPO model accounts for incomparability using three sets of parameters.
First, it incorporates the _difficulty_ of each question's responses, that is, how much interest in politics is indicated by a given response. 
This is most evident with respect to response categories: to say that one is "very interested" in politics, for example, is to exhibit more interest than to say that one is "somewhat interested" or "not very interested."
Here, difficulty is permitted to vary with question wording and the survey project as well.
Second, the DCPO model accounts for each question's _dispersion_, its noisiness with regard to our latent trait.
The lower the dispersion, the better that changes in responses to the question map onto changes in macrointerest.
Third, to provide for the possibility that translation issues or cultural differences result in the same question being interpreted differently in different countries, the model estimates _country-specific bias_ parameters that shift the difficulty of all responses for a particular question in a particular country.
Together, the model's difficulty, dispersion, and country-specific bias parameters work to generate comparable estimates of the latent variable of macrointerest from the available but incomparable source data.^[
See a discussion of how other data issues, such as sample representation, may affect the estimated outcome in Appendix\nobreakspace{}\@ref(dcpo).]

To address the sparsity of the source data---the fact that there are gaps in the time series of each country, and that even many observed country-years have only one or two observed items---DCPO uses simple local-level dynamic linear models, i.e., random-walk priors, for each country.
That is, within each country, each year's value of macrointerest is modeled as the previous year's estimate plus a random shock.
These dynamic models smooth the estimates of macrointerest over time and allow estimation even in years for which little or no survey data is available, albeit at the expense of greater measurement uncertainty.

```{r dcpo_input, eval=FALSE, include=FALSE, results=FALSE}
dcpo_input <- DCPOtools::format_dcpo(dcpo_input_raw1,
                                     scale_q = "int4_ess",
                                     scale_cp = 2)
save(dcpo_input, file = here::here("data", "dcpo_input.rda"))
```

```{r dcpo, eval=FALSE, include=FALSE, results=FALSE}
iter <- 1000

dcpo <- paste0(.libPaths(), "/DCPO/stan/dcpo.stan")[1] |> 
  cmdstan_model()

dcpo_output <- dcpo$sample(
   data = dcpo_input[1:13], 
   max_treedepth = 14,
   adapt_delta = 0.99,
   step_size = 0.005,
   seed = 324, 
   chains = 4, 
   parallel_chains = 4,
   iter_warmup = iter/2,
   iter_sampling = iter/2,
   refresh = iter/50
 )

results_path <- here::here(file.path("data", 
                                     iter, 
                                  {str_replace_all(Sys.time(),
                                                      "[- :]",
                                                   "") %>%
                                         str_replace("\\d{2}$",
                                                     "")}))

dir.create(results_path, 
           showWarnings = FALSE, 
           recursive = TRUE)

dcpo_output$save_data_file(dir = results_path,
                           random = FALSE)
dcpo_output$save_output_files(dir = results_path,
                              random = FALSE)
```

```{r dcpo_output, eval=FALSE}
if (!exists("results_path")) {
  latest <- "202304201035"
  results_path <- here::here("data", "1000", latest)

  # Define OSF_PAT in .Renviron: https://docs.ropensci.org/osfr/articles/auth
  if (!file.exists(file.path(results_path, paste0("dcpo-", latest, "-1.csv")))) {
    dir.create(results_path,
               showWarnings = FALSE,
               recursive = TRUE)
    osf_retrieve_node("9uvdk") %>%
      osf_ls_files() %>%
      filter(str_detect(name, latest)) %>%
      osf_download(path = here::here("data", "1000"))
  }
}

load(file = here::here("data", "dcpo_input.rda"))
dcpo_output <- as_cmdstan_fit(here::here(results_path,
                                         list.files(results_path,
                                                    pattern = "csv$")))

theta_summary <- DCPOtools::summarize_dcpo_results(dcpo_input,
                                                   dcpo_output,
                                                   "theta")

save(theta_summary, file = here::here("data",
                                      "theta_summary.rda"))

theta_results <- extract_dcpo_results(dcpo_input,
                                      dcpo_output,
                                      par = "theta")

save(theta_results, file = here::here("data",
                                      "theta_results.rda"))

alpha_results <- summarize_dcpo_results(dcpo_input,
                                        dcpo_output = dcpo_output,
                                        pars = "alpha") %>% 
  transmute(item = question,
            dispersion = mean)

beta_results <- summarize_dcpo_results(dcpo_input,
                                       dcpo_output,
                                       "beta") %>% 
  group_by(question) %>% 
  summarize(difficulties0 = paste0(sprintf("%.2f", round(mean, 2)),
                                   collapse = ", ")) %>% 
  mutate(item = question,
         cp = if_else(str_detect(item, "threestate"),
                      2, 
                      as.numeric(str_extract(item, "\\d+")) - 1),
         term = str_glue("(( ?-?[0-9].[0-9][0-9]?,?){{{cp}}})"),
         difficulties = str_extract(difficulties0, 
                                    term) %>%
           str_replace(",$", "") %>% 
           str_trim()) %>% 
  transmute(item, difficulties)

save(alpha_results,
     beta_results,
     file = here::here("data",
                       "item_results.rda"))
```

```{r theta_summary}
load(file = here(here("data", "theta_summary.rda")))
load(here("data", "theta_results.rda"))

res_cy <- nrow(theta_summary) %>% 
  scales::comma()

res_c <- theta_summary %>% 
  pull(country) %>% 
  unique() %>% 
  length()
```

The model was estimated using the `DCPOtools` package for R [@Solt2019], running four chains for 1,000 iterations each and discarding the first half as warmup, leaving 2,000 samples.
The $\hat{R}$ diagnostic had a maximum value of 1.01, indicating that the model converged. <!-- macrointerest Rhat confirmed -->
The dispersion parameters of the survey items indicate that all of them load well on the latent variable (see Appendix\nobreakspace{}\@ref(surveys)).
The result is estimates, in all `r res_cy` country-years spanned by the source data, of the mean political interest of the public, that is, macrointerest.


# Validating Cross-National Macrointerest {.unnumbered}

That we can generate estimates of macrointerest does not automatically mean that they are suitable for analysis. 
As is the case for any new measure, validation tests of cross-national latent variables are crucially important [see, e.g., @Hu2023].
Figure\nobreakspace{}\@ref(fig:internalval) and Figure\nobreakspace{}\@ref(fig:extval1) provide evidence of this measure's validity with tests of convergent validation and construct validation.
Convergent validation refers to tests of whether a measure is empirically associated with alternative indicators of the same concept [@Adcock2001, 540].
In Figure\nobreakspace{}\@ref(fig:internalval), the macrointerest scores are compared to responses to individual source-data survey items that were used to generate them; this provides an 'internal' convergent validation test [see, e.g., @Caughey2019, 686, in which the correlations between the estimated variable and other indicators vary from 0.65 to 0.96.
Be aware that correlations can be also affect by data richness, survey context, and other factors.].

In the left panel, macrointerest scores are plotted against the percentage of respondents across all country-years who offered the two most interested responses on the European Social Survey's four-point item, "How interested are you in politics?"
The middle panel shows responses to the question with the most data-rich cross-section, "How interested would you say you personally are in politics?" in the International Social Survey Program's 2004 module on Citizenship.
Finally, the right panel evaluates how well the macrointerest scores capture change over time by focusing on the item with the largest number of observations for a single country in the source data, which asked respondents to Germany's ALLBUS, "How interested in politics are you?"
In all three cases, the correlations, estimated taking into account the uncertainty in the measures, are strong.

```{r internal_val_dat}
internal_tscs_dat <- dcpo_input_raw1 %>% 
  filter(item == "int4_ess") %>%  
  mutate(title = "European Social Survey",
         neg = FALSE)

internal_cs_dat <- dcpo_input_raw1 %>% 
  filter(survey == "issp2004") %>%  
  mutate(title = "ISSP Citizenship I, 2004",
         neg = FALSE)

internal_ts_dat <- dcpo_input_raw1 %>% 
  filter(item == "int5_allbus") %>%  
  mutate(title = "Germany",
         neg = FALSE)
```

```{r internalval, fig.height = 3.5, fig.cap = "Internal Convergent Validation: Correlations Between Macrointerest and Individual Source-Data Survey Items"}
load(here("data", "theta_summary.rda"))
load(here("data", "theta_results.rda"))

internal_tscs_plot <- validation_plot(internal_tscs_dat,
                                lab_x = .1,
                                lab_y = 95) +
  theme_bw() +
  theme(legend.position="none",
        axis.text  = element_text(size=8),
        axis.title = element_text(size=9),
        plot.title = element_text(hjust = 0.5, size = 8),
        strip.background = element_blank()) +
  coord_cartesian(xlim = c(0,1), ylim = c(0,100)) +
  labs(x = "Macrointerest",
       y = "% 'Very' or 'Quite' Interested in Politics")

internal_cs_plot <- validation_plot(internal_cs_dat,
                                lab_x = .1,
                                lab_y = 95) +
  theme_bw() +
  theme(legend.position="none",
        axis.text  = element_text(size=8),
        axis.title = element_text(size=9),
        plot.title = element_text(hjust = 0.5, size = 8),
        # strip.text.x = element_text(size=5),
        strip.background = element_blank()) +
  coord_cartesian(xlim = c(0,1), ylim = c(0,100)) +
  labs(x = "Macrointerest",
       y = "% 'Very' or 'Fairly' Interested in Politics")

internal_ts_plot <- validation_plot(internal_ts_dat,
                                    lab_x = 1987,
                                    lab_y = .95) +
  theme_bw() +
  theme(legend.position="none",
        axis.text  = element_text(size=8),
        axis.title = element_text(size=9),
        plot.title = element_text(hjust = 0.5, size = 9),
        strip.background = element_blank()) +
  coord_cartesian(ylim = c(0,1)) +
  labs(x = "Year",
       y = "Score") +
  annotate("text", x = 1995, y = .22, size = 2,
           label = 'ALLBUS') +
  annotate("text", x = 2008, y = .7, size = 2,
           label = "Macrointerest")

internal_tscs_plot + internal_cs_plot + internal_ts_plot  +
  patchwork::plot_annotation(caption = "Note: Gray whiskers and shading represent 80% credible intervals.")
```

```{r ext_val_dat, eval=FALSE}
ext_dat <- read_csv(here("data-raw",
                         "surveys_ext.csv"),
                    col_types = "cccccc") %>% 
  DCPOtools::dcpo_setup(datapath = here("..",
                                        "data",
                                        "dcpo_surveys"),
                        file = here("data",
                                    "ext_dat.csv"))
```

```{r ext_dat, include=FALSE}
ext_dat <- read_csv(here("data",
                         "ext_dat.csv"),
                    col_types = "cdcddcd")

ext_wvs_disc_dat <- ext_dat %>%
  filter(str_detect(item, "disc3")) %>% 
  mutate(title = "",
         neg = FALSE)

ext_wvs_news_dat <- ext_dat %>%
  filter(str_detect(item, "news5")) %>% 
  mutate(title = "",
         neg = FALSE)

ext_wvs_imp_dat <- ext_dat %>%
  filter(str_detect(item, "imp4")) %>%
    mutate(title = "",
           neg = FALSE)
```

```{r extval1, fig.cap="Construct Validation: Correlations Between Macrointerest and Other Aspects of Political Engagement", fig.height=3.5}
ext_wvs_news_plot <- validation_plot(ext_wvs_news_dat,
                                     lab_x = .15,
                                     lab_y = 95) +
  theme_bw() +
  theme(legend.position="none",
        axis.text  = element_text(size=8),
        axis.title = element_text(size=9),
        plot.title = element_text(hjust = 0.5, size = 9),
        strip.background = element_blank()) +
  coord_cartesian(xlim = c(0,1), ylim = c(0,100)) +
  labs(x = "Macrointerest",
       y = "% Who Follow Politics in Traditional Media\nDaily or Several Times a Week")

ext_wvs_disc_plot <- validation_plot(ext_wvs_disc_dat,
                                    lab_x = .15,
                                    lab_y = 95) +
  theme_bw() +
  theme(legend.position="none",
        axis.text  = element_text(size=8),
        axis.title = element_text(size=9),
        plot.title = element_text(hjust = 0.5, size = 9),
        strip.background = element_blank()) +
  coord_cartesian(xlim = c(0,1), ylim = c(0,100)) +
  labs(x = "Macrointerest",
       y = "% Who Discuss Politics with Friends")

ext_wvs_imp_plot <- validation_plot(ext_wvs_imp_dat,
                                       lab_x = .13,
                                       lab_y = 95) +
  theme_bw() +
  theme(legend.position="none",
        axis.text  = element_text(size=8),
        axis.title = element_text(size=9),
        plot.title = element_text(hjust = 0.5, size = 9),
        strip.background = element_blank()) +
  coord_cartesian(xlim = c(0,1), ylim = c(0,100)) +
  labs(x = "Macrointerest",
       y = "% Saying Politics is 'Very' or 'Rather'\nImportant in Their Lives")

ext_wvs_news_plot + ext_wvs_disc_plot + ext_wvs_imp_plot +
  plot_annotation(
    # subtitle = "World Values Study and European Values Study",
    caption = "Note: Gray whiskers and shading represent 80% credible intervals. Survey\nitems sourced from World Values Study and European Values Study.")
```

Construct validation, on the other hand, refers to demonstrating, for some _other_ concept believed causally related to the concept a measure seeks to represent, that the measure is empirically associated with measures of that other concept [@Adcock2001, 542].
Figure\nobreakspace{}\@ref(fig:extval1) depicts the relationships between macrointerest and three survey items from the World Values Survey and European Values Survey on other aspects of political engagement that are expected to have causal relationships with political interest [see @Kittilson2010, 995]: in the left panel, following political news on television, radio, and newspapers; in the center panel, discussing politics with friends; and on the right, feeling politics is important to one's life.
These relationships are all positive and are moderate to strong.
This cross-national latent variable of macrointerest performs impressively well in validation tests.


# Testing Theories of Macrointerest Cross-Nationally {.unnumbered}

Macrointerest varies greatly around the world, even across the relatively similar countries like the advanced democracies.
Figure\nobreakspace{}\@ref(fig:ts_plots) examines levels and trends in macrointerest in advanced democratic countries by displaying the changes of the public's expressed interest in politics over time in the thirty-seven democracies of the OECD.^[
Appendix \@ref(trajectory) presents these data for all available countries.]
While macrointerest scores approach and often exceed .6 in countries such as Denmark and Canada, in Chile they scarcely cross .25.
And although the public's political interest has held fairly steady over decades in many countries, in Czechia it dropped nearly half of the variable's entire theoretical range over the 1990s and 2000s before rebounding slightly since 2010, and increases of roughly a quarter of that range can be seen in, among others, Germany. 
There are considerable differences in the extent to which the public professes interest in politics both across countries and over time.

```{r ts, fig.cap="Macrointerest Scores Over Time Within OECD Democracies \\label{ts_plots}", fig.height=9}

load(here::here("data", "theta_summary.rda"))

oecd_countries <- c("Australia", "Austria", "Belgium",
                    "Canada", "Chile", "Colombia",
                    "Costa Rica", "Czechia", "Denmark",
                    "Estonia", "Finland", "France", 
                    "Germany", "Greece", "Hungary",
                    "Iceland", "Ireland", "Israel",
                    "Italy", "Japan", "South Korea",
                    "Latvia", "Lithuania", "Luxembourg",
                    "Mexico", "Netherlands", "New Zealand",
                    "Norway", "Poland", "Portugal", 
                    "Slovakia", "Slovenia", "Spain",
                    "Sweden", "Switzerland", "Turkey", 
                    "United Kingdom", "United States")

c_res <- theta_summary %>% 
  filter(country %in% oecd_countries) %>%
  mutate(country = fct_reorder(country, mean, .desc = TRUE))

ggplot(data = c_res, aes(x = year, y = mean)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(1982, 2022), ylim = c(0, 1)) +
  labs(x = NULL, y = "Macrointerest") +
  geom_ribbon(data = c_res, aes(ymin = q10, ymax = q90, linetype=NA), alpha = .25) +
  geom_line(data = c_res) +
  facet_wrap(~country, ncol = 5) +
  theme(axis.text.x  = element_text(size=7,
                                    angle = 90,
                                    vjust = .45,
                                    hjust = .95),
        strip.background = element_rect(fill = "white", colour = "white")) +
  plot_annotation(caption = "Note: Countries are ordered by their median macrointerest score; gray shading represents 80% credible intervals.")
```

What explains these differences?
One straightforward explanation is that publics grow more interested in politics at election time.
Campaigns and elections attract media coverage and increase the information available to the public on the issues being contested, leading to increased interest in politics [see, e.g., @Larsen2022].
Macrointerest within each country should be expected to be higher, therefore, in years in which national elections take place than in years without elections.

A second argument is that political institutions that share power, rather than concentrate it, yield politics that are more interesting and engaging.
Building on @Lijphart1999 and @Powell2000, @Kittilson2010 [, 992] argues that power-sharing institutions---parliamentarism, federalism, and proportional electoral rules---"send signals of inclusiveness to citizens, generating greater political engagement" while power-concentrating institutions "may generate perceptions of exclusion and deter involvement."
Macrointerest should be higher in countries with parliamentary and federal systems than in those without those features, and it should decline as the disproportionality between votes cast and seats won increases.

A third claim deals with the public's demand for accountability.
@Peterson2022 [, 203] advances this argument: "when there is information that something has gone wrong \ldots then voters should be more likely to attend to the actions of elected officials," but when "there is evidence of success \ldots voters should not waste their energies."
If democracy is a principal-agent problem with elected officials acting as self-interested agents and the public as their lazy but vengeful principal, then macrointerest should rise when times are bad and decline as conditions improve.

A final set of theories---each well established---contradicts the third.
Modernization theory holds that the public's interest in politics will increase as the national economy grows and household incomes expand [see, e.g., @Inglehart2005].
Unemployment has long been argued to not to motivate but rather to depress political interest [see, e.g., @Rosenstone1982, 26].
And the relative power theory holds that greater income inequality, by increasingly concentrating political power in the hands of the wealthy, allows them greater power to shape the political agenda in ways that discourage the broader public from taking interest [see, e.g., @Solt2008].
In each of these circumstances, macrointerest is argued to increase in good, not bad, economic conditions [see also @Stimson2015; @Peterson2022, 206].

Data to test these hypotheses regarding the causes of macrointerest are drawn from several sources.
The Democratic Electoral Systems (DES) dataset updated in @Bormann2022 provides information about the timing of elections, yielding a dichotomous variable coded one in election years and zero when no election was held.
The three institutional variables are measured as in @Kittilson2010.
Data on parliamentarism, a dichotomous variable coded one in pure parliamentary systems and zero otherwise, is also sourced from the DES.
Federalism is a third dichotomous variable, coded one in countries with strong federal systems [see @Lijphart1999] and zero in all others.
The proportionality of the electoral system is measured using the Gallagher least-squares index of disproportionality, which measures the disparity between parties' vote shares and their seat shares [@Gallagher1991, 40-41].
The context of good times and bad was measured with data on GDP per capita, national GDP growth, and unemployment from OECD.Stat [@OECD2023] and on the Gini index of disposable income inequality from the Standardized World Income Inequality Database [@Solt2020].

```{r des_download}
if (!file.exists(here("data-raw", "es_data-v41", "es_data-v4_1.csv"))) {
  dir.create(here("data-raw", "es_data-v41"))
  download.file("http://mattgolder.com/files/research/es_v4_codebook.pdf",
                here("data-raw", "es_data-v41", "es_v4_codebook.pdf"))
  download.file("http://mattgolder.com/files/research/es_data-v41.zip",
                here("data-raw", "es_data-v41", "es_data-v41.zip"))
  unzip(here("data-raw", "es_data-v41", "es_data-v41.zip"),
        exdir = here("data-raw", "es_data-v41"))
}
```

```{r des}
des_data <- vroom::vroom(here("data-raw",
                              "es_data-v41",
                              "es_data-v4_1.csv"),
                         guess_max = 5000,
                         show_col_types = FALSE) %>% 
  mutate(country = countrycode(country,
                               origin = "country.name",
                               destination = "country.name",
                               custom_match = c("Serbia & Montenegro" =
                                                  "Serbia",
                                                "The Co-operative Republic of Guyana" = "Guyana"))) %>% 
  filter(country %in% oecd_countries &
           country!="Turkey" &
           year > 1976) %>% 
  arrange(country, year) %>% 
  fill() %>% 
  group_by(country, year) %>% 
  summarize(regime = first(regime))

# enpp1 = if_else(max(enpp1, na.rm = TRUE)!=-Inf,
#                 max(enpp1, na.rm = TRUE),
#                 NA_real_) %>% 
#  mutate(enpp1 = if_else(!is.na(enpp1), enpp1, lag(enpp1)))
```

```{r disp}
if (!file.exists(here("data-raw", "ElectionIndices.pdf"))) {
  download.file("https://www.tcd.ie/Political_Science/about/people/michael_gallagher/ElSystems/Docts/ElectionIndices.pdf",
                here("data-raw", "ElectionIndices.pdf"))
}

gallegher_uk <- extract_text(here("data-raw", "ElectionIndices.pdf"),
                               pages = 46,
                               area = list(c(69,
                                        86, 
                                        111, 
                                        424)))[[1]] %>% 
  as_tibble() %>% 
  separate_longer_delim(value, " \n") %>% 
  separate(value, into = c("year", "lsq", "n_v", "n_s", "seats"), sep = "\\s") %>% 
  mutate(country = "United Kingdom",
         year = as.numeric(year),
         lsq = as.numeric(lsq),
         n_v = as.numeric(n_v), 
         n_s = as.numeric(n_s),
         seats = as.numeric(seats)) %>% 
  filter(!is.na(year))

# disp_add <- repmis::source_data(url = "https://raw.githubusercontent.com/christophergandrud/Disproportionality_Data/master/Disproportionality.csv")

disp_add <- rio::import(here("data-raw", "Disproportionality.csv")) %>% 
  filter((country == "Korea, Republic of" & year < 2004) | (country == "Colombia")) %>% 
  select(country, year, lsq = disproportionality) %>% 
  mutate(country = countrycode(country, "country.name", "country.name"))

gallegher0 <- map_df(5:48, ~ extract_tables(here("data-raw", "ElectionIndices.pdf"),
                                           pages = c(.x))[[1]] %>% 
    as_tibble())

gallegher <- gallegher0 %>% 
  mutate(V1 = case_when(V1 == "Republic" ~ "Dominican Rep",
                        V1 == "Ireland LSq" ~ "Northern Ireland",
                        V1 == "Kingdom" ~ "United Kingdom",
                        V1 == "(House)" ~ "United States",
                        V1 == "Scotland" ~ "Scotland",
                        TRUE ~ V1),
         country = countrycode(V1, "country.name", "country.name"),
         country = case_when(V1 == "elections" ~ "Ireland EP",
                             V1 == "college)" ~ "U.S. Electoral College",
                             V1 == "Ireland LSq" ~ "Northern Ireland",
                             V1 == "Wales" ~ "Wales",
                             V1 == "Principe" ~ "Principe",
                              TRUE ~ country),
         country2 = country) %>% 
  fill(country) %>% 
  filter(is.na(country2) & !V1 == "See Notes.") %>% 
  separate_wider_delim(V1, 
                       delim = " ", 
                       names = c("year", "info"),
                       too_few = "align_start",
                       too_many = "merge") %>% 
  mutate(lsq = str_replace_all(info, "[^\\d.]", ""),
         V2 = if_else(V2 == "", lsq, V2),
         month = str_extract(info, "[A-Z][a-z]{2}\\b") %>% 
           match(month.abb)) %>% 
  filter((is.na(info) | !str_detect(info, "PR|list|SMD|SMP")) ) %>% 
  transmute(country = country,
            year = as.numeric(year),
            lsq = as.numeric(V2),
            info = info,
            month = month) %>% 
  filter(!is.na(lsq)) %>% 
  bind_rows(gallegher_uk, disp_add) %>% 
  group_by(country, year) %>% 
  arrange(country, -year, -month) %>% 
  distinct(country, year, .keep_all = TRUE) %>% 
  arrange(country, year) %>% 
  select(country, year, lsq)
    
```

```{r oecd}
if (!file.exists(here::here("data-raw", "oecd_data.rda"))) {
  
  oecd_growth_link <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/SNA_TABLE1/AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.B1_GE.G/all?startTime=1980&endTime=2022"
  
  oecd_growth <- oecd_growth_link %>% 
    readSDMX() %>% 
    as_tibble() %>% 
    transmute(country = countrycode(LOCATION, "iso3c", "country.name"),
              year = as.numeric(obsTime),
              growth = obsValue)
  
  oecd_unemployment_link <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/LFS_SEXAGE_I_R/AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.MW.1564.UR.A/all?startTime=1980&endTime=2022"
  
  oecd_unemp <- oecd_unemployment_link %>% 
    readSDMX() %>% 
    as_tibble() %>% 
    transmute(country = countrycode(COUNTRY, "iso3c", "country.name"),
              year = as.numeric(obsTime),
              unemployment = obsValue)
  
  oecd_inflation_link <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/PRICES_CPI/AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.CPALTT01.GY.A/all?startTime=1980&endTime=2023"
  
  oecd_inf <- oecd_inflation_link %>% 
    readSDMX() %>% 
    as_tibble() %>% 
    transmute(country = countrycode(LOCATION, "iso3c", "country.name"),
              year = as.numeric(obsTime),
              inflation = obsValue)
  
  oecd_gdppc_link <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/SNA_TABLE1/AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.B1_GE.HVPVOB/all?startTime=1980&endTime=2022"
  
  oecd_gdppc <- oecd_gdppc_link %>% 
    readSDMX() %>% 
    as_tibble() %>% 
    transmute(country = countrycode(LOCATION, "iso3c", "country.name"),
              year = as.numeric(obsTime),
              gdppc = obsValue)
  
  oecd <- oecd_gdppc %>% 
    left_join(oecd_growth, by = c("country", "year")) %>% 
    left_join(oecd_unemp, by = c("country", "year")) %>% 
    left_join(oecd_inf, by = c("country", "year")) %>% 
    group_by(country) %>% 
    mutate(across(gdppc:inflation,
                  ~ imputeTS::na_interpolation(.x)))
  
  rio::export(oecd, here::here("data-raw", "oecd_data.rda"))
} else {
  oecd <- rio::import(here::here("data-raw", "oecd_data.rda"))
}

```

```{r swiid_data}
if (!file.exists(here("data-raw",
                      "swiid9_4",
                      "swiid9_4_summary.csv"))) {
  download.file("https://dataverse.harvard.edu/api/access/datafile/6716676", "data-raw/swiid9_4.zip")
  unzip(here("data-raw", "swiid9_4.zip"), exdir = here("data-raw"))
  file.remove("data-raw", "swiid9_4.zip")
}

swiid_summary <- read_csv(here("data-raw",
                               "swiid9_4",
                               "swiid9_4_summary.csv")) %>% 
  mutate(country = countrycode::countrycode(country,
                                            "country.name",
                                            "country.name")) %>% 
  select(country, year, gini_disp, gini_disp_se)
```

```{r analysis, include=FALSE}
data_combo <- theta_summary %>% 
    filter(country %in% oecd_countries &
             country!="Turkey") %>% 
    group_by(country) %>% 
    group_modify(~ add_row(.x, year = 0:4, .before = 0)) %>%
    mutate(year = case_when(year == 0 ~ lead(year, 5) - 5,
                            year == 1 ~ lead(year, 4) - 4,
                            year == 2 ~ lead(year, 3) - 3,
                            year == 3 ~ lead(year, 2) - 2,
                            year == 4 ~ lead(year, 1) - 1,
                            TRUE ~ year)) %>% 
    left_join(des_data, by = c("country", "year")) %>%
    mutate(parl = if_else(regime == 0, 1, 0),
           election = as.numeric(!is.na(regime))) %>% 
    select(-regime) %>% 
    fill(parl) %>% 
    left_join(oecd,
              by = c("country", "year")) %>% 
    left_join(swiid_summary,
              by = c("country", "year")) %>% 
    left_join(gallegher,
              by = c("country", "year")) %>% 
    fill(lsq) %>% 
    drop_na(mean:lsq) %>% 
    mutate(federal = as.numeric(country %in% c("Australia", # decentralized = strong
                                               "Belgium",
                                               "Canada",
                                               "Germany",
                                               "Mexico",
                                               "Switzerland",
                                               "United States")),
           lsq_mean = mean(lsq),
           lsq_diff = lsq - lsq_mean,
           gini_mean = mean(gini_disp),
           gini_mean_se = sqrt(sum(gini_disp_se^2))/
             length(gini_disp),
           gini_diff = (gini_disp - gini_mean),
           gini_diff_se = sqrt(gini_disp_se^2 + gini_mean_se^2)/2,
           gdppc_mean = mean(gdppc/1000),
           gdppc_diff = gdppc/1000 - gdppc_mean,
           growth_mean = mean(growth),
           growth_diff = growth - growth_mean,
           recession = if_else(growth >= 0, 0, 1),
           unemploy_mean = mean(unemployment),
           unemploy_diff = unemployment - unemploy_mean,
           inflation_mean = mean(inflation),
           inflation_diff = inflation - inflation_mean) %>% 
    ungroup()

if (!file.exists(here::here("data", "results.rda"))) {
  m1 <- brm(
    formula = bf(
      mean * 100 | mi(sd * 100) ~ election +
        parl +
        federal +
        lsq_mean + lsq_diff +
        gdppc_mean + gdppc_diff +
        growth_mean + growth_diff +
        unemploy_mean + unemploy_diff +
        me(gini_mean, gini_mean_se) +
        me(gini_diff, gini_diff_se) +
        (1 | country) + (1 | year)
    ),
    data = data_combo,
    backend = "cmdstanr",
    warmup = 1000,
    iter = 2000,
    chains = 4,
    cores = parallel::detectCores(),
    seed = 324
  )
  
  doubled_sd <- m1$data %>% 
    select(-`mean * 100`, -mean, -sd,
           -country, -year, -ends_with("_se")) %>% 
    summarize(across(everything(), by2sd)) %>% 
    pivot_longer(everything()) %>% 
    transmute(`.variable` = case_when(name == "gini_mean" ~ 
                                        "bsp_megini_meangini_mean_se",
                                      name == "gini_diff" ~
                                        "bsp_megini_diffgini_diff_se",
                                      TRUE ~ paste0("b_", name)),
              var_names = c("Election Year",
                            "Parliamentarism",
                            "Federalism",
                            "Disproportionality, Mean",
                            "Disproportionality, Difference",
                            "GDPpc, Mean",
                            "GDPpc, Difference",
                            "GDP Growth, Mean",
                            "GDP Growth, Difference",
                            "Unemployment, Mean",
                            "Unemployment, Difference",
                            "Income Inequality, Mean",
                            "Income Inequality, Difference"),
              sd2 = value)
  
  coef_data0 <- m1 %>% 
    tidybayes::gather_draws(`bs?p?_.*`, regex = TRUE) %>% 
    filter(!`.variable`=="b_Intercept") %>% 
    left_join(doubled_sd, by = join_by(.variable))
  
  cy_summary <- m1$data %>%
    count(country) %>%
    pull(n) %>%
    summary()

  save(m1, doubled_sd, coef_data0, cy_summary, file = here::here("data", "results.rda"))
} else {
  load(file = here::here("data", "results.rda"))
}

ess_perc <- ess_perc <- {{dcpo_input_raw1 %>% 
    filter(country %in% oecd_countries & r==1) %>%
    count(item) %>%
    arrange(desc(n)) %>%
    slice(1) %>%
    pull(n)} * 100 / nrow(m1$data)} %>% 
  round()
```

The resulting dataset comprises the thirty-seven OECD democracies, each observed in twenty-one (Mexico) to forty (Ireland, Italy, the United Kingdom, and the United States) consecutive years (mean: `r cy_summary %>% nth(4) %>% round(1)` years, median: `r cy_summary %>% nth(3)` years).
Even among these relatively data-rich countries, our measure of macrointerest provides much more data than would otherwise be available: the richest single survey for these cases, the European Social Survey, covers only `r ess_perc`% of these country-years, and of course excludes entirely the nine OECD members in the Americas and around the Pacific Rim (see Appendix\nobreakspace{}\@ref(whyOecd)).

@Shor2007 demonstrates that such pooled time series are best analyzed using a Bayesian multilevel model including varying intercepts for each country and each year. 
The former help account for heteroskedasticity across space due to, e.g., omitted variable bias, while permitting the inclusion of time-invariant predictors such as, in this dataset, parliamentarism and federalism.
The latter take into account 'time shocks' that operate on all countries simultaneously [@Shor2007, 171-172].
Further, the 'within-between random effects' specification is employed, meaning each of the time-varying predictors is decomposed into its time-invariant country mean and the difference between each country-year value and this country mean; this specification has been shown superior to fixed effects and other commonly used TSCS specifications for addressing omitted variable bias and endogeneity [see @Bell2015].
The time-varying difference variables capture the short-term effects of the predictors, while the time-invariant country-mean variables reflect their---often different---long-run, "historical" effects [@Bell2015, 137].
The measurement uncertainty in the data for both macrointerest and income inequality was incorporated into the analysis with the "method of composition," a technique frequently utilized across numerous studies in political science [e.g., @CaugheyWarshaw2018a; @KastellecEtAl2015; @TaiEtAl2022a].
(See Supplementary Material C of @TaiEtAl2022a for a comprehensive review and application instruments in the DCPO framework.)
The model was estimated using the `brms` R package [@Burkner2017].

```{r resplot, fig.cap="Predicting Macrointerest in OECD Democracies \\label{model}", fig.height = 5.5, fig.width = 7.5}

ordered <- doubled_sd %>%
  pull(var_names) %>% 
  rev()

coef_data <- coef_data0 %>% 
  mutate(std_coef = round(.value * sd2, 1),
         term = factor(var_names, levels = ordered)) %>%
  ggdist::median_qi(std_coef, .width = c(.8, .9, .95)) %>%
  mutate(ci = paste0(round(.lower, 1), " to ", round(.upper, 1))) %>%
  left_join(doubled_sd, ., by = join_by(.variable))

coef_data0 %>% 
  mutate(std_coef = .value * sd2,
         term = factor(var_names, levels = ordered)) %>% 
  ggplot(aes(y = term, x = std_coef)) +
  stat_halfeye(.width = c(.8, .9, .95)) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  coord_cartesian(xlim = c(-15, 15)) +
  theme_light() +
  xlab(NULL) +
  ylab(NULL) +
  plot_annotation(caption = "Notes: Dots indicate posterior means; whiskers, from thickest to thinnest, describe 80%,\n90%, and 95% credible intervals; shading depicts the posterior probability density function.")
```


Figure\nobreakspace{}\@ref(fig:resplot) displays the results (see the numeric results in Appendix\nobreakspace{}\@ref(whyOecd).
Consistent with the argument that campaigns bring attention-grabbing information to the public, the posterior distribution shows a 95% probability that macrointerest in election years is `r get_coef("election", type = "ci")` higher than in years without elections.
This is in line with previous research finding small but well-estimated increases in political interest in election years [see, e.g., @Larsen2022].

The hypothesis that power-sharing institutions yield more public interest in politics is also supported.
It is a 95% confident that macrointerest is `r get_coef("parl", type = "ci")` points higher in countries with parliamentary systems, according to the posterior probabilities.
The difference between countries with and without federalism is estimated to be even larger on average (`r get_coef("federal", type = "std_coef")`, cp. `r get_coef("parl", type = "std_coef")` for parliamentarism), though only 90% confidence is bounded away from zero.
And although disproportionality is not estimated to have long-run effects that consistently distinguish countries with more or less proportional electoral results, _changes_ in disproportionality appear to have an immediate negative effect: a two-standard-deviation increase in the Gallagher index has 95% confidence reducing `r get_coef("lsq_diff", type = "ci")` points of macrointerest.

On the debate on whether macrointerest is invigorated or instead discouraged by bad times, the evidence from this cross-national analysis falls heavily on the side of the latter.
Supporting modernization theory, increases in per capita GDP have a well estimated positive short-term effect on aggregate political interest, with a two-standard-deviation increase associated with `r get_coef("gdppc_diff", type = "ci")` points more macrointerest (with 95% credibility).
The long-term, historical effect as evidenced by differences in mean levels across countries is found to be larger, `r get_coef("gdppc_mean", type = "ci", width = 0.8)` points but only with 80% confidence.
The effect for growth in the national economy are positive as well, but there is not enough credibility to distinguish it from zero according to the posterior probabilities.
The findings with regard to unemployment are similar.
Supporting the relative power theory, the posterior distribution indicates 95% credibility that the long-term effects of income inequality may cause `r get_coef("gini_mean", type = "ci")` points macrointerest reduction with every two-standard-deviation difference across countries on average.
Year-to-year changes in income inequality are found to make little difference---the influence of the wealthy over the political agenda, it would seem, does not change on such a short time scale, from one perspective, and there is no evidence that the public reacts to worsening conditions in the distribution of income with greater interest in its agents' actions, from the other.
Taken as a whole, evidence moderately supports the notion that absolute economic growth, rather than depression, is associated with increased macrointerest, while the distributional bias in economic growth outcomes consistently diminishes macrointerest.

# Conclusions {.unnumbered}

Macrointerest, despite its theoretical importance, has as yet drawn only limited empirical attention.
This oversight largely reflects the paucity of available data to measure this important concept.
The cross-national macrointerest dataset presented here addresses this issue, providing annual time series across more than a hundred countries and allowing more and better tests of the wide range of theories that implicate the public's interest in politics.
For example, while the cross-sectional analysis in @Kittilson2010 [, 997-999] found that, among the three inclusive institutions it considered, only the disproportionality of electoral results influenced political interest and engagement, the pooled time-series analysis presented here indicates parliamentarism, federalism, and proportionality all yield greater macrointerest as @Kittilson2010 theorized.
And although the single-country study in @Peterson2022 [, 219] concludes that bad times prompt increased macrointerest, this evidence shows just the opposite, that it is _good_ times that lead the public to take interest in politics.
By drawing on information about _both_ differences across countries _and_ change over time, it appears these data on cross-national macrointerest provide a firmer basis for drawing sound conclusions.
<!-- Beyond investigating the sources of macrointerest, the novel cross-national measurement also provide opportunity for further examining its relationship with various types of political participation and civil engagements [@Anderson2007;@VerbaEtAl1995]. -->
The cross-national macrointerest dataset is available on the Harvard Dataverse for use in the further investigation of these and other theories on the causes and consequences of aggregate political interest as well as its relationships with other aspects of political engagement.


\pagebreak

# References {.unnumbered}

::: {#refs-text}
:::

\pagebreak

# (APPENDIX) Appendix {-} 

```{=tex}
\renewcommand{\baselinestretch}{1}
\selectfont
\maketitle
\selectfont
```
```{=tex}
\pagenumbering{arabic}
\renewcommand*{\thepage}{A\arabic{page}}
```
```{=tex}
\setcounter{figure}{0}
\renewcommand*{\thefigure}{A\arabic{figure}}
```
```{=tex}
\setcounter{table}{0}
\renewcommand*{\thetable}{A\arabic{table}}
```
```{=tex}
\vspace{-.5in}
\begin{center}
\begin{Large}
Appendices
\end{Large}
\end{center}
```

# Survey Items Used to Estimate Macrointerest {#surveys}

National and cross-national surveys have often included questions tapping interest in politics over the past four decades, but the resulting data are both sparse, that is, unavailable for many countries and years, and incomparable, generated by many different survey items.
In all, we identified `r n_items` such survey items that were asked in no fewer than five country-years in countries surveyed at least twice; these items were drawn from `r n_surveys` different survey datasets.

The full list of source surveys is presented in Table \@ref(tab:surveyInfo), and the items used from the surveys are also explicitly listed in Table \@ref(tab:itemTb).
Apart from the country-years of each analytic itmes, we also present their dispersion ($\alpha$) and difficulty ($\beta$) scores estimated from the DCPO model.
Lower values of dispersion indicate questions that better identify publics with a higher level of trust from those with lower.
Items have one less difficulty score than the number of response categories.

Survey dataset codes correspond to those used in the `DCPOtools` R package [@Solt2019]; they appear in decreasing order of country-years contributed.
In accordance with the advice offered by @Hu2022 to avoid data-entry errors by automating data collection, the `DCPOtools` R package [@Solt2019] was used to compile the responses to these questions.
The current version of the software facilitates the entire practical data generation process, from accessing original survey datasets to their conversion into R-compatible formats, and to restructuring them for analysis with the DCPO model. 
The primary objective is to limit manual interventions, thereby reducing error potential inherent in human-operated data preparation tasks.

Together, the survey items in the source data were asked in `r n_countries` different countries in at least two time points over `r n_years` years, `r year_range`, yielding a total of `r n_cyi` country-year-item observations.
The number of items observed in the source data for each country-year is plotted in Figure\nobreakspace{}\@ref(fig:obs) below.
The macrointerest scores of country-years with more observed items are likely to be estimated more precisely.
The estimates for country-years with fewer (or no) observed items rely more heavily (or entirely) on the random-walk prior and are therefore less certain.

```{r surveyInfo}
tb_survey <- import(here("data-raw", "survey_info_macrointerest.xlsx"),
                    sheet = "combined") |>
  mutate(
    survey = str_remove(survey, "\\d+") |>
      str_remove(",.*") |>
      str_remove("_.*"),
    creator = ifelse(
      creator == str_to_upper(creator),
      str_to_title(creator),
      creator
    ),
    version = ifelse(is.na(version), "", str_to_lower(version))
  ) |>
  select(-link, -survey) |>
  filter(!is.na(name)) |> 
  group_by(name) |>
  summarise(
    year = ifelse(
      min(year) == max(year),
      as.character(year),
      paste0(min(year), "-", max(year))
    ),
    version = paste(unique(version), collapse = ", "),
    creator = paste(unique(creator), collapse = "; ")
  ) |>
  mutate(creator = stringi::stri_trans_general(creator, "Latin-ASCII")) |> 
  set_names(c("Survey", "Range", "Version", "Primary Creator/Maintainer"))

names(tb_survey)[3] <- paste0(names(tb_survey)[3], footnote_marker_symbol(1))

datasummary_df(tb_survey, 
               title = "Source Survey Information",
               longtable = TRUE) |> 
  kable_styling(latex_options = c("striped", "repeat_header")) |> 
  column_spec(1, width = "20em") |> 
  column_spec(2, width = "7em") |> 
  column_spec(3, width = "6em") |> 
  column_spec(4, width = "30em") |> 
  kable_styling(font_size = 7) |> 
  footnote(symbol = "The abbreviations are given according to the source surveys' naming styles on their editions, including edition (e.), part (p.), round (r.), version (v.), and wave (w.).", threeparttable = T)

```

```{r macrointerest_items}
load(here::here("data", "dcpo_input.rda"))
load(here::here("data", "item_results.rda"))

items_summary <- dcpo_input_raw1 %>%
  dplyr::select(country, year, item, survey) %>%
  distinct() %>%
  separate(survey, c("surv1", "surv2", "surv3"), sep=", ", fill = "left") %>%
  pivot_longer(cols = starts_with("surv"), values_to = "survey") %>%
  filter(!is.na(survey)) %>% 
  group_by(item) %>% 
  mutate(survey = str_extract(survey, "^[a-z]*"),
         all_surveys = paste0(unique(survey), collapse = ", ")) %>% 
  ungroup() %>% 
  distinct(country, year, item, .keep_all = TRUE) %>% 
  group_by(item) %>% 
  mutate(n_cy = n()) %>% 
  ungroup() %>%
  distinct(item, n_cy, all_surveys) %>% 
  left_join(surveys_interest %>%
              select(item, question_text, response_categories) %>%
              distinct(item, .keep_all = TRUE),
            by = "item") %>% 
  left_join(alpha_results, by = "item") %>% 
  left_join(beta_results, by = "item") %>% 
  arrange(-n_cy)
```

```{r itemsTb}  
items_summary %>% 
  mutate(item = str_replace(item, "_", ".")) |> 
  select(-item, -all_surveys) |> 
  transmute(`Country-Years` = as.character(n_cy),
            `Question Text` = str_replace(question_text, "([^(]*)\\(.*", "\\1"),
            `Response Categories` = response_categories,
            `Dispersion` = dispersion,
            `Difficulties`= difficulties) %>% 
  datasummary_df(longtable = TRUE, 
                 title = "Indicators Used in the Latent Variable Model of Macrointerest") %>% 
  column_spec(1, width = "3em") %>%
  column_spec(2, width = "24em") %>%
  column_spec(3, width = "20em") %>%
  column_spec(4, width = "4em") %>%
  column_spec(5, width = "10em") %>%
  kable_styling(font_size = 7) %>%
  kable_styling(latex_options = c("striped", "repeat_header"))
```


```{r obs, fig.cap = "Source Data Observations by Country and Year", fig.height = 9}
dcpo_input_plot <- dcpo_input_raw1 %>% 
  mutate(country = str_replace(country, "’", "'"),
         country = if_else(country %in% oecd_countries & country!="Turkey",
                           paste0(country, "*"),
                           country)) %>% 
  distinct(country, year, item, cc_rank) %>% 
  group_by(country, year) %>% 
  summarize(n = n(),
            cc_rank = mean(cc_rank)) %>% 
  ungroup() %>% 
  distinct() |> 
  mutate(continent = countrycode(country, "country.name", "continent",
                                 warn = FALSE), 
         continent = case_when(country %in% c("Kosovo", "Northern Ireland") ~
                                 "Europe",
                               continent %in% c("Asia", "Oceania") ~
                                 "Asia-Oceania",
                               TRUE ~ continent)) %>% 
  group_by(continent) %>% 
  mutate(mean_cc_rank = mean(cc_rank),
         continent = as_factor(continent))

dcpo_input_plot %>%
  filter(continent %in% c("Europe", "Asia-Oceania")) %>%
  ggplot(aes(x = year, 
             y = forcats::fct_reorder(country, cc_rank),
             fill = n)) + 
  geom_tile() +
  scale_fill_stepsn(colors = rev(hcl.colors(7, "inferno")),
                    n.breaks = 7,
                    show.limits = TRUE,
                    right = FALSE,
                    name = "Observations") +
  labs(x = NULL, y = NULL) +
  scale_x_continuous(breaks=seq(1982, 2022, 4)) +
  scale_y_discrete(position = "right") +
  theme(axis.text.y  = element_text(size = 7),
        strip.background = element_rect(fill = "white", colour = "white")) +
  facet_wrap(~forcats::fct_reorder(continent, mean_cc_rank, .desc = TRUE),
             ncol = 1,
             scales = "free") +
  plot_annotation(caption = "Starred countries are OECD democracies, the sample employed in the analysis of macrointerest presented in the main text.")
```

```{r obs2, fig.cap = "Source Data Observations by Country and Year, cont.", fig.height = 9}

dcpo_input_plot %>%
  filter(!continent %in% c("Europe", "Asia-Oceania")) %>%
  ggplot(aes(x = year, 
             y = forcats::fct_reorder(country, cc_rank),
             fill = n)) + 
  geom_tile() +
  scale_fill_stepsn(colors = rev(hcl.colors(7, "inferno")),
                    limits = c(1, 7),
                    show.limits = TRUE,
                    right = FALSE,
                    name = "Observations") +
  labs(x = NULL, y = NULL) +
  scale_x_continuous(breaks=seq(1982, 2022, 4),
                     sec.axis = dup_axis()) +
  scale_y_discrete(position = "right") +
  theme(axis.text.y  = element_text(size = 7),
        strip.background = element_rect(fill = "white", colour = "white")) +
  facet_wrap(~forcats::fct_reorder(continent, mean_cc_rank, .desc = TRUE),
             ncol = 1,
             scales = "free") +
  plot_annotation(caption = "Starred countries are OECD democracies, the sample employed in the analysis of macrointerest presented in the main text.")
```

\pagebreak

# The DCPO Model {#dcpo}

A number of recent studies have developed latent variable models of aggregate survey responses based on cross-national survey data [see @Claassen2019; @Caughey2019; @McGann2019; @Kolczynska2020].
To estimate macrointerest across countries and over time, we employ the latest of these methods that is appropriate for data that is not only incomparable but also sparse, the Dynamic Comparative Public Opinion (DCPO) model elaborated in @Solt2020c.
The DCPO model is a population-level two-parameter ordinal logistic item response theory (IRT) model with country-specific item-bias terms.

DCPO models the total number of survey responses expressing at least as much macrointerest as response category $r$ to each question $q$ in country $k$ at time $t$, $y_{ktqr}$, out of the total number of respondents surveyed, $n_{ktqr}$, using the beta-binomial distribution:

\begin{equation}
a_{ktqr} = \phi\eta_{ktqr} \label{eq:bb_a}
\end{equation}
\begin{equation}
b_{ktqr} = \phi(1 - \eta_{ktqr}) \label{eq:bb_b}
\end{equation}
\begin{equation}
y_{ktqr} \sim \textrm{BetaBinomial}(n_{ktqr}, a_{ktqr}, b_{ktqr}) \label{eq:betabinomial}
\end{equation}

where $\phi$ represents an overall dispersion parameter to account for additional sources of survey error beyond sampling error and $\eta_{ktqr}$ is the expected probability that a random person in country $k$ at time $t$ answers question $q$ with a response at least as interested as response $r$.^[
The ordinal responses to question $q$ are coded to range from 1 (expressing the least political interest) to $R$ (expressing the most political interest), and $r$ takes on all values greater than 1 and less than or equal to $R$.]

This expected probability, $\eta_{ktqr}$, is in turn estimated as follows:

\begin{equation}
\eta_{ktqr} = \textrm{logit}^{-1}(\frac{\bar{\theta'}_{kt} - (\beta_{qr} + \delta_{kq})}{\sqrt{\alpha_{q}^2 + (1.7*\sigma_{kt})^2}}) \label{eq:dcpo}
\end{equation}

In this equation, $\beta_{qr}$ represents the difficulty of response $r$ to question $q$, that is, the degree of political the response expresses.  The $\delta_{kq}$ term represents country-specific item bias: the extent to which all responses to a particular question $q$ may be more (or less) difficult in a given country $k$ due to translation issues, cultural differences in response styles, or other idiosyncrasies that render the same survey item not equivalent across countries.^[
Estimating $\delta_{kq}$ requires repeated administrations of question $q$ in country $k$, so
when responses to question $q$ are observed in country $k$ in only a single year, the DCPO model sets $\delta_{kq}$ to zero by assumption, increasing the error of the model by any country-item bias that is present.
Questions that are asked repeatedly over time in only a single country pose no risk of country-specific item bias, so $\delta_{kq}$ in such cases are also set to zero.]
The dispersion of question $q$, its noisiness in relation to the latent variable, is $\alpha_{q}$. The mean and standard deviation of the unbounded latent trait of macrointerest are $\bar{\theta'}_{kt}$ and $\sigma_{kt}$, respectively.

Random-walk priors are used to account for the dynamics in $\bar{\theta'}_{kt}$ and $\sigma_{kt}$, and weakly informative priors are placed on the other parameters.^[
The dispersion parameters $\alpha_{q}$ are drawn from standard half-normal prior distributions, that is, the positive half of N(0, 1).
The first difficulty parameters for each question, $\beta_{q1}$, are drawn from standard normal prior distributions, and the differences between $\beta$s for each $r$ for the same question $q$ are drawn from standard half-normal prior distributions.
The item-bias parameters $\delta_{kq}$ receive normally-distributed hierarchical priors with mean 0 and standard deviations drawn from standard half-normal prior distributions.
The initial value of the mean unbounded latent trait for each country, $\bar{\theta'}_{k1}$, is assigned a standard normal prior, as are the transition variances $\sigma_{\bar{\theta'}}^2$ and $\sigma_{\sigma}^2$; the initial value of the standard deviation of the unbounded latent trait for each country, $\sigma_{k1}$, is drawn from a standard lognormal prior distribution.
The overall dispersion, $\phi$, receives a somewhat more informative prior drawn from a gamma(4, 0.1) distribution that yields values that are well scaled for that parameter.]
The dispersion parameters $\alpha_q$ are constrained to be positive and all survey responses are coded with high values indicating more political interest to fix direction.
The difficulty $\beta$ of "to some extent" (the third response on the four-point, "not at all" to "a great deal" scale) to the European Social Survey's question "To what extent would you say you are interested in politics?" is set to 1 to identify location, and for each question $q$ the difficulties for increasing response categories $r$ are constrained to be increasing.
The sum of $\delta_{kq}$ across all countries $k$ is set to zero for each question $q$:

\begin{equation}
\sum_{k = 1}^K \delta_{kq} = 0
\end{equation}

Finally, the logistic function is used to transform $\bar{\theta'}_{kt}$ to the unit interval and so give the bounded mean of macrointerest, $\bar{\theta}_{kt}$, which is our parameter of interest here [see @Solt2020c, 3-8].^[
Alternative approaches exist for transforming data to the unit interval.
For example, a probit transformation, that is, the cumulative distribution function (CDF) of the normal distribution is one option, one that facilitates the interpretation of the values of the resulting measure as percentiles.
The advantage of the logistic transformation compared to the probit transformation is its heavier tails, which allow for differences among very low and among very high values to be distinguished more clearly.]

The DCPO model accounts for the incomparability of different survey questions with two parameters.
First, it incorporates the _difficulty_ of each question's responses, that is, how much political interest is indicated by a given response. 
That each response evinces more or less of our latent trait is most easily seen with regard to the ordinal responses to the same question: indicating that one is "strongly interested" exhibits more political interest than stating one is "fairly interested," which is a more interested response that "not very interested," which in turn is more interested than "not at all."
But this is also true across questions.
For example, indicating that politics is among "the sort of things in life interest you a lot" likely expresses even more interest than agreeing that one is interested in politics "most of the time."
Second, the DCPO model accounts for each question's _dispersion_, its noisiness with regard to our latent trait.
The lower a question's dispersion, the better that changes in responses to the question map onto changes in macrointerest.
Together, the model's difficulty and dispersion estimates work to generate comparable estimates of the latent variable of macrointerest from the available but incomparable source data.

To address the sparsity of the source data---the fact that there are gaps in the time series of each country, and even many observed country-years have only one or few observed items---DCPO uses simple local-level dynamic linear models, i.e., random-walk priors, for each country.
That is, within each country, each year's value of macrointerest is modeled as the previous year's estimate plus a random shock.
These dynamic models smooth the estimates of macrointerest over time and allow estimation even in years for which little or no survey data is available, albeit at the expense of greater measurement uncertainty.

It is noteworthy that the quality of DCPO estimates partly hinges on the source data's quality. 
While extensive data input and the Bayesian process might mitigate issues from problematic sources, other Total Survey Error aspects, notably representation errors, can still influence outcomes and lead to comparison errors.
DCPO addresses measurement scale inconsistencies across surveys; however, variations in population definitions (such as age range, minority inclusion, and territorial exclusions) and sample designs (like probability versus non-probability samples, and older surveys' reliance on quota or random route samples without enumeration) remain a concern. 
These variations in data collection processes affect representation levels, impacting the estimation of broader interests like macrointerest.

DCPO can adjust for sampling biases using survey weights. 
However, for unweighted surveys, it doesn't offer a specific solution.
Methodologically, leveraging census or other population data to correct biases is feasible (as demonstrated by @CaugheyWarshaw2015 in their DGIRT model). 
The trade-off is much longer time and much higher requirement of calculation power to converge the results. 
(As @CaugheyWarshaw2015[n. 8] indicated, the run times for the method incorporating census-based correction "ranged between a day and several weeks.")
Additionally, not all surveys have suitable population data for correction, posing a challenge in balancing information richness against data representation. 
In this study, we applied weighing to surveys with weights through DCPO but did not specifically adjust for those without.

We urge researchers using DCPO in future projects to pay close attention to the sample design of the source data (e.g., the documentation of Latinobarometro states that some samples cover less than 20% of the given country) and be mindful of the potential risks of Total Survey Errors from including all available data. 
We also encourage further scholarly examination of our findings' robustness through alternative source data selection strategies.



# Case Selection and Data Improvement for the Hypothesis Testing {#whyOecd}

After creating the cross-sectional time-series macrointerest, we tested theories of macrointerest formation in thirty-seven democracies of the OECD. 
Most macrointerest formation-modification theories assume stable and enduring democratic institutions.
OECD countries are generally characterized by stable political systems and developed economies. 
This stability provides a consistent backdrop for analyzing how macrointerest form and evolve over time, minimizing the impact of extreme political or economic upheavals that could skew data in less stable contexts.
While the OECD countries commit to democratic governance and market-based economies, there are also sufficient cultural, political, socioeconomic, and geographic diversities among them.
This combination of diversity and comparability allows for robust cross-national studies and the testing of theories across different yet relatable settings.
The high quality political and socioeconomic data of these countries also reduce the influence of measurement error and data sparseness on the analytic outcomes.

While most OECD countries have rich data, they are not always yearly continuous.
Nor are the datasets are comparable.
DCPO helps to maximize the useful information from these sparse data and achieve a full time-range cross-sectional examination of the theoretical inferences.
Figure \@ref(fig:cpOECD) visualize the increment DCPO yields in comparison with one of the largest and oft-used dataset for OECD countries, the European Election Survey (EES).
The year ranges covered by ESS is marked as the light bars by year, and those DCPO can offer are marked dark.
DCPO not only fills all the empty years absent from EES but also extend the data availability beyond Europe to the entire rank of OECD countries and from 1982 to 2022.

```{r cpOECD, fig.cap="Data Availability: DCPO vs. ESS", fig.height=5}
if (!file.exists(here("data", "tb_ess.rda"))) {
  library(rvest)
  tb_ess <-
    read_html("https://www.europeansocialsurvey.org/about/participating-countries") |>
    html_element(".table-wrapper , td , th") |>
    html_table()
  
  names(tb_ess)[1] <- "country"
  
  save(tb_ess, file = here::here("data", "tb_ess.rda"))
} else {
  load(here("data", "tb_ess.rda"))
}

tb_ess_oecd <- filter(tb_ess, country %in% setdiff(oecd_countries, "Turkey")) |> 
  mutate(across(-country, \(x) ifelse(x == "", 0, 1))) |> 
  pivot_longer(cols = -country, 
               names_to = "year",
               values_to = "available_ess") |> 
  mutate(year = sub("R\\d{1}", "", year) |> as.numeric())

tb_dcpo_oecd <- theta_summary %>% 
  filter(country %in% setdiff(oecd_countries, "Turkey")) %>% 
  select(country, year) %>%
  mutate(available_dcpo = 1)

tb_oecd <- left_join(tb_dcpo_oecd, tb_ess_oecd) |> 
  mutate(available = rowSums(across(c(available_dcpo, available_ess)), na.rm = TRUE),
         available_fct = factor(available, labels = c("DCPO", "ESS"))) |> 
  select(country, year, available, available_fct)

ggplot(tb_oecd, aes(x = year, 
             y = country,
             fill = available_fct)) + 
  geom_tile() +
  labs(x = NULL, y = NULL) +
  scale_fill_manual(values = hcl.colors(5, "inferno", alpha = 0.6)[c(2, 4)]) +
  scale_x_continuous(breaks=seq(1982, 2022, 4),
                     sec.axis = dup_axis()) +
  scale_y_discrete(position = "right") +
  theme(axis.text.y  = element_text(size = 7),
        legend.title = element_blank(),
        legend.position = "top") 
```

Table \@ref(tab:modelTB) presents the hypothesis testing result based on this data. 
The result has been visualized in Figure \@ref(fig:resplot) and discussed in the main text.
We welcome future researchers to examine our findings on other country cases, especially those not commonly participating in the same survey program or have more sparse data.
The examination requires more efforts on model specification to address the even larger socioeconomic and political variance among non-OECD countries.

```{r modelTB, cache=TRUE}
vec_coefName <- c(
  "b_election" = "Election Year",
  "b_parl" = "Parliamentarism",
  "b_federal" = "Federalism",
  "b_lsq_mean" = "Disproportionality, Mean",
  "b_lsq_diff" = "Disproportionality, Difference",
  "b_gdppc_mean" = "GDPpc, Mean",
  "b_gdppc_diff" = "GDPpc, Difference",
  "b_growth_mean" = "GDP Growth, Mean",
  "b_growth_diff" = "GDP Growth, Difference",
  "b_unemploy_mean" = "Unemployment, Mean",
  "b_unemploy_diff" = "Unemployment, Difference",
  "bsp_megini_meangini_mean_se" = "Income Inequality, Mean",
  "bsp_megini_diffgini_diff_se" = "Income Inequality, Difference"
)

# Create a modelsummary table with the number of observations included
modelsummary(
  m1,
  coef_map = vec_coefName,
  statistic = "conf.int",
  notes = "95-percent credible intervals are in brackets.",
  title = "Numeric results of Figure 5",
  booktabs = TRUE
)
```


# Macrointerest Scores Over Time {#trajectory}

```{r trajectory, fig.align='center', fig.height=9}
df_plot_fullCountry <- theta_summary %>%  
  mutate(continent = countrycode(country, "country.name", "continent",
                                 warn = FALSE), 
         continent = case_when(country %in% c("Kosovo", "Northern Ireland") ~
                                 "Europe",
                               continent %in% c("Asia", "Oceania") ~
                                 "Asia-Oceania",
                               TRUE ~ continent),
         continent = factor(continent, levels = c("Europe", "Asia-Oceania", "Americas", "Africa")),
         country = fct_reorder(country, mean, .desc = TRUE))

ls_plot_fullCountry <- split(df_plot_fullCountry, df_plot_fullCountry$continent)

fun_plot <- function(data){
  ggplot(data, aes(x = year, y = median, group = country)) +
    theme_bw() +
    coord_cartesian(xlim = c(1982, 2022), ylim = c(0, 1)) +
    geom_line() +  # Line for median
    geom_ribbon(aes(ymin = q10, ymax = q90), alpha = 0.25) +  # Shaded area for credible interval
    theme(axis.text.x  = element_text(size=7,
                                    angle = 90,
                                    vjust = .45,
                                    hjust = .95),
        strip.background = element_rect(fill = "white", colour = "white")) +
    labs(
      title = data$continent,
      x = "Year",
      y = "Macrointerest",
      caption = "Note: Countries are ordered by their median macrointerest score; gray shading represents 80% credible intervals."
    ) +
    facet_wrap(~ country, ncol = 5)  # Creates a separate plot for each country
}

plot_fullCountry <- ls_plot_fullCountry |>
  map(fun_plot)

plot_fullCountry[[1]]
plot_fullCountry[[2]]
plot_fullCountry[[3]]
plot_fullCountry[[4]]
```

```{r presentationPlot, eval=FALSE}
df_plot_illustrate <- filter(df_plot_fullCountry, country %in% c("China", "Russia", "United States")) 

ggplot(df_plot_illustrate, aes(x = year, y = median, fill = country)) +
    geom_line() +  # Line for median
    geom_ribbon(aes(ymin = q10, ymax = q90), alpha = 0.25) +  # Shaded area for credible interval
  coord_cartesian(xlim = c(1990, 2020)) + 
  drhutools::scale_fill_gb(palette = "digitMixed", reverse = TRUE) +
    theme(axis.text.x  = element_text(size=7,
                                    angle = 90,
                                    vjust = .45,
                                    hjust = .95),
        strip.background = element_rect(fill = "white", colour = "white")) +
    labs(x = "Year",
      y = "Macrointerest",
      caption = "Note: Countries are ordered by their median macrointerest score; gray shading represents 80% credible intervals."
    )

ggsave(here("output", "macroint_interestURC.png"))
```


# Comparison with @Peterson2022 {#peterson}

This study extends the pivotal concept of "macrointerest" from @Peterson2022, but it is not intended to replicate that paper: both the method and data employed diverge considerably between the two projects.
Still, a comparison of the macrointerest estimates generated for the United States in both projects is valuable.

Our work diverges methodologically by employing the Dynamic Comparative Public Opinion (DCPO) model instead of the dyad ratio algorithm, commonly referred to as "Wcalc," used by @Peterson2022 [, 208]. 
Apart from the primary rationale stated in the main text---that Wcalc is inherently tailored for generating public opinion time series within a single country rather than for cross-national comparison---there are also methodological and operational distinctions between these two approaches.

The dynamic ratio algorithm primarily seeks to uncover shared variance over time among various survey items.
Its process involves initially pairing these items, subsequently calculating the ratio for each unique pair, and then analyzing the distribution of these ratios. 
DCPO instead directly models the relationship between the latent variable and survey item responses using a Bayesian Item Response Theory (IRT) approach (for more on the differences between dyad ratios and IRT, see @McGann2014, which finds that a single-country IRT model provides a better fit to a collection of UK public opinion data meant to capture "policy mood" than the dyad ratio algorithm). 
The DCPO method provides a probabilistic framework, enabling the estimation of response probabilities contingent on both the level of the latent trait and specific characteristics of the survey items (for more details, see Appendix\nobreakspace{}\@ref(dcpo)).

Additionally, these methods adopt differing strategies for addressing missing data at certain time points. 
The dynamic ratio algorithm tackles this challenge by estimating values for unobserved series at each time point, basing these estimations on the calculated ratio of missing survey items to those observed in the corresponding period.
For the same issue, DCPO, on the other hand, employs dynamic linear models at the local level for each country, leveraging random-walk priors. 
This approach not only smooths the estimates of macrointerest over time but also facilitates estimation in years characterized by limited or absent survey data and simultaneously provides specific uncertainty estimates.

As @Peterson2022 [, 210] points out, to conduct the dyad ratio algorithm, researchers must first dichotomize each survey question by collapsing responses and (possibly, as in this case) excluding moderate opinions.
DCPO, on the other hand, incorporates an ordered logistic model and so does require the transformation of any of the original item responses.
It also produces credible intervals of the estimates from the Bayesian process, rather than relying on ex-post bootstrapping for uncertainty estimation.
DCPO additionally implements a logistic function to confine the outcome estimates within the unit interval. 

Finally, it is worth noting that the data employed in each paper differs.
The estimates of @Peterson2022 are based on sixteen series with observations in at least two quarters.
The data on which our macrointerest estimates for the United States are based on eleven series with at least five country-year observations across all countries.
These latter data are dated annually, and nearly all of them are drawn from cross-national surveys.
Only two series, drawn from the American National Election Survey and from surveys by the Pew Research Center, are included in both source-data datasets.
This is due partly to the minimum of five country-year observations we use, partly to the shorter time span covered by this project (because of the paucity of data for other countries in earlier decades), partly to our practice of using only surveys for which the entire survey dataset rather than only survey marginals is available to ensure survey weights are applied, partly to the omission of cross-national surveys by @Peterson2022, and partly to the combination of these factors.

```{r peterson, eval=FALSE}
source(here("data", "peterson2022", "Extract.r"))

macroint2 <- import(here("data", "peterson2022", "calc2.dta"))

# make the date variable in the right format
macroint2$date2 <- ISOdate(macroint2$year, macroint2$month, 1)

# Create the macrointerest measure

interestQ <-
  extract(
    macroint2$varname,
    as.Date(macroint2$date2),
    macroint2$index3,
    macroint2$ncases,
    unit = "Q",
    begindt = ISOdate(1973, 1, 1),
    enddt = NA
  )

# bootstrap

set.seed(96345)

n.boot <- 1000  #number of iterations

boot.est <-
  matrix(NA, nrow = 168, ncol = n.boot) #create the empty matrix that the results will go in.  nrow is the number of final time points

for (i in 1:n.boot) {
  #make the new "index" which is the input to the calc algorithm.  This is a draw from a random normal with mean and sd based on real results
  macroint2$index4 <-
    rnorm(349 , mean = macroint2$index3, sd = sqrt(((macroint2$ncases * macroint2$index) * (1 - macroint2$index) ^ 2 + (macroint2$ncases * (1 - macroint2$index)) * (0 - macroint2$index) ^ 2) / (macroint2$ncases - 1)))
  #run calc.  Save the outout as "object"
  object <-
    extract(
      macroint2$varname,
      as.Date(macroint2$date2),
      macroint2$index4,
      macroint2$ncases,
      unit = "Q",
      begindt = ISOdate(1973, 1, 1),
      enddt = NA
    )
  #add the measure of the macrointerest measure to the appropriate col of the boot.est
  boot.est[, i] <- object$latent1
  #read in the data with the surveys by house
}

##pull out the mean and sd of bootstrapped results
MI.est <-
  matrix(NA, nrow = 168, ncol = 4) #create the empty matrix that the results will go in.  nrow is the number of final time points
MI.est[, 1] <- interestQ$period
MI.est[, 2] <- interestQ$latent1
MI.est[, 3] <- apply(boot.est, 1, mean)
MI.est[, 4] <- apply(boot.est, 1, sd)

MI <- tibble(
  period = interestQ$period,
  latent1 = interestQ$latent1,
  boot_mean = apply(boot.est, 1, mean),
  boot_sd = apply(boot.est, 1, sd)
)

saveRDS(MI, here("data", "peterson2022", "peterson_mi.rds"))

```

```{r peterson-plot, fig.align='center', fig.cap="Comparison between DCPO and Wcalc"}
MI <- readRDS(here("data", "peterson2022", "peterson_mi.rds"))

df_peterson2022 <- MI |> 
  transmute(quarter = (period - round(period)) * 10,
            year = round(period) + (2*quarter-1)*.125,
            mean = boot_mean/100 - .25,
            se = boot_sd/100,
            lb = mean - qnorm(0.9) * se,
            ub = mean + qnorm(0.9) * se) |> 
  mutate(method = "Wcalc")

df_dcpo <- filter(c_res, country == "United States") |> 
  select(year, mean, lb = q10, ub = q90, se = sd) |> 
  mutate(method = "DCPO")

df_compare <- df_peterson2022 %>% 
  bind_rows(df_dcpo)

compare_cor <- c_res %>% 
  filter(country == "United States") %>% 
  left_join(df_peterson2022 %>% 
              mutate(year = floor(year)) %>% 
              group_by(year) %>% 
              summarize(mean_wcalc = mean(mean),
                        se_wcalc = mean(se)),
            by = "year") %>% 
  with(cor(mean_wcalc, mean, use = "pairwise.complete.obs")) %>% 
  round(2) %>% 
  paste("R =", .)

plot_comparison <- ggplot(data = df_compare,
                          aes(x = year, y = mean, group = method, fill = method)) +
  labs(y = "Macrointerest", title = "Wcalc vs. DCPO") +
  coord_cartesian(xlim = c(1982, 2014)) +
  geom_ribbon(data = df_compare, aes(ymin = lb, ymax = ub), alpha = .5) +
  geom_line() +
  plot_annotation(caption = "Shaded areas represent 80% credible intervals.") +
  theme_bw() +
  scale_x_continuous(breaks = seq(1982, 2016, by = 4)) +
  theme(axis.title.x = element_blank(), 
        legend.title = element_blank(), 
        legend.position = c(0.1, 0.2)) +
  annotate(geom = "text", 
           x = 1985,
           y = .62,
           label = compare_cor)

plot_comparison

```

In Figure \@ref(fig:peterson-plot), we compare the outcomes from these two methods during the years they overlap, from 1982 to 2014.
For the purpose of this comparison, the Wcalc scores of @Peterson2022 are first divided by 100 to place them on the unit interval and then shifted a quarter-point downward, which yields identical scores on both series in their first common year, 1982.
Neither of these affect the shape of the Wcalc series; they work simply to overlay the two series for more straightforward comparison.

Two points stand out.
First, the credible intervals of the DCPO series are considerably broader than the bootstrapped intervals for the Wcalc series.
Whether these latter intervals are overconfident seems worth investigating, perhaps by cross-validation, by future users of this method.
Second, the two series are positively but not particularly strongly related; the bivariate correlation is just `r compare_cor`.
The surge in macrointerest after the September 11, 2001 attacks documented in @Peterson2022 [, 217], for example, is brief in the Wcalc series but longer-lasting in the DCPO series.
Conversely, the sharp upturn in the Wcalc macrointerest series that peaks in late 2013 does not appear in the DCPO series at all---it appears to be an artifact of the rather thin data in the Knowledge Networks series @Peterson2022 employs (see also @Peterson2022, Appendix C, which drops these observations as anomalous).

```{r pmsm}
pmsm <- haven::read_dta(here("data", 
                             "peterson2022",
                             "macrointerest_R.dta")) %>% 
  mutate(trust_lag = lag(trust),
         trust_diff = trust - trust_lag,
         prapp_lag = lag(prapp),
         prapp_diff = prapp - prapp_lag,
         ics_lag = lag(ics),
         ics_diff = ics - ics_lag,
         interest_lag = lag(interest))

pmsm_annual <- pmsm %>% 
  group_by(year) %>% 
  summarize(trust = mean(trust),
            prapp = mean(prapp),
            ics = mean(ics),
            prezcamp = mean(prezcamp),
            september = max(september),
            interest = mean(interest)) %>% 
  left_join(df_dcpo, by = join_by(year)) %>% 
    mutate(trust_lag = lag(trust),
         trust_diff = trust - trust_lag,
         prapp_lag = lag(prapp),
         prapp_diff = prapp - prapp_lag,
         ics_lag = lag(ics),
         ics_diff = ics - ics_lag,
         interest_lag = lag(interest),
         dcpo = mean*100,
         dcpo_lag = lag(dcpo))

m_pmsm <- lm(interest ~ interest_lag +
               trust_lag +
               trust_diff +
               prapp_lag +
               prapp_diff +
               ics_lag +
               ics_diff +
               prezcamp +
               september, 
              data = pmsm %>% filter(between(year, 1983, 2014)))

m_pmsm_ann <- lm(interest ~ interest_lag +
               trust_lag +
               trust_diff +
               prapp_lag +
               prapp_diff +
               ics_lag +
               ics_diff +
               prezcamp +
               september, 
              data = pmsm_annual %>% filter(!is.na(dcpo_lag)))

m_pmsm_dcpo <- lm(dcpo ~ dcpo_lag +
                    trust_lag +
                    trust_diff +
                    prapp_lag +
                    prapp_diff +
                    ics_lag +
                    ics_diff +
                    prezcamp +
                    september, 
                  data = pmsm_annual %>% filter(!is.na(dcpo_lag)))

vec_coefName2 <- c(
  "interest_lag" = "Macrointerest (Lagged)",
  "dcpo_lag" = "Macrointerest (Lagged)",
  "trust_lag" = "Trust (Lagged)",
  "trust_diff" = "Trust (Difference)",
  "prapp_lag" = "Presidential Approval (Lagged)",
  "prapp_diff" = "Presidential Approval (Difference)",
  "ics_lag" = "Consumer Sentiment (Lagged)",
  "ics_diff" = "Consumer Sentiment (Difference)",
  "prezcamp" = "Presidential Election",
  "september" = "September 11"
)

gm <- tibble::tribble(
  ~raw,        ~clean,          ~fmt,
  "nobs",      "N",             0,
  "r.squared", "R2", 3,
  "rmse", "RSME", 2)

# Create a modelsummary table with the number of observations included
modelsummary(
  list("Wcalc" = m_pmsm,
       "Annual Wcalc" = m_pmsm_ann,
       "DCPO" = m_pmsm_dcpo),
  coef_map = vec_coefName2,
  statistic = "std.error",
  stars = TRUE,
  gof_map = gm,
  title = "Replication of Peterson et al. (2022), Table 2, 1983-2014",
  booktabs = TRUE
)
```

The two series are further compared in Table \@ref(tab:pmsm).
The first column replicates the analysis of @Peterson2022, Table 2, using only the years from 1983 to 2014, that is, the span for which DCPO estimates of macrointerest are also available.
To preserve degrees of freedom, of the eight scandals and negative events, only the dummy variable for the attacks of September 11, 2001 (the only one to receive support in @Peterson2022) is included.
The findings of @Peterson2022 are reproduced in this truncated dataset.

In the second column, the @Peterson2022 Wcalc macrointerest data are aggregated to the annual level over the same period, that is, each year's value is the mean of the values of that year's quarters, and the independent variables were similarly annualized.
Over this time period and at this unit of analysis, macrointerest is predicted only by its lagged value: the coefficients for trust, presidential elections, and September 11 no longer reach statistical significance.
The DCPO macrointerest series for the United States yields similar results.
It would appear that it is the unit of analysis---years as opposed to quarters--- rather than the macrointerest series, that yields different conclusions in the @Peterson2022 analysis.

\clearpage
\pagebreak

# References {.unnumbered}

::: {#refs-app}
:::